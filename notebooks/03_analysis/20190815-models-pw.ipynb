{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/96/84/4e2cae6247f397f83d8adc5c2a2a0c5d7d790a14a4c7400ff6574586f589/xgboost-0.90.tar.gz (676kB)\n",
      "\u001b[K    100% |████████████████████████████████| 686kB 6.5MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/ptw/anaconda3/lib/python3.7/site-packages (from xgboost) (1.16.2)\n",
      "Requirement already satisfied: scipy in /Users/ptw/anaconda3/lib/python3.7/site-packages (from xgboost) (1.2.1)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Building wheel for xgboost (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/ptw/Library/Caches/pip/wheels/e9/48/4d/de4187b5270dff71d3697c5a7857a1e2d9a0c63a28b3462eeb\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-0.90\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting merf\n",
      "  Downloading https://files.pythonhosted.org/packages/2c/67/857915b2fecbe73b6ef6c6c05fb532967af1c9ec4bedb9ca3eb648f71a1f/merf-0.3-py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn in /Users/ptw/anaconda3/lib/python3.7/site-packages (from merf) (0.21.3)\n",
      "Requirement already satisfied: numpy in /Users/ptw/anaconda3/lib/python3.7/site-packages (from merf) (1.16.2)\n",
      "Requirement already satisfied: pandas in /Users/ptw/anaconda3/lib/python3.7/site-packages (from merf) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/ptw/anaconda3/lib/python3.7/site-packages (from scikit-learn->merf) (0.13.2)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/ptw/anaconda3/lib/python3.7/site-packages (from scikit-learn->merf) (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /Users/ptw/anaconda3/lib/python3.7/site-packages (from pandas->merf) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/ptw/anaconda3/lib/python3.7/site-packages (from pandas->merf) (2018.9)\n",
      "Requirement already satisfied: six>=1.5 in /Users/ptw/anaconda3/lib/python3.7/site-packages (from python-dateutil>=2.5.0->pandas->merf) (1.12.0)\n",
      "Installing collected packages: merf\n",
      "Successfully installed merf-0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install merf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housevotes_df = pd.read_csv('../../data/02_intermediate/HouseVotesFeatures_12_18_0814PM.csv')\n",
    "housevotes_df = pd.read_csv('../../data/04_models/ACS_HouseVotes_L1_14_18_0815.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305, 278)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housevotes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1305, 278)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housevotes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yr_district_id',\n",
       " 'year_x',\n",
       " 'state',\n",
       " 'district_id_x',\n",
       " 'winner_voteshare',\n",
       " 'total_dem_vote_share',\n",
       " 'total_rep_vote_share',\n",
       " 'dL1_winner',\n",
       " 'dL2_winner',\n",
       " 'dL3_winner',\n",
       " 'dL4_winner',\n",
       " 'dL5_winner',\n",
       " 'incumbent_L5_races',\n",
       " 'incumbent_L4_races',\n",
       " 'incumbent_L3_races',\n",
       " 'incumbent_L2_races',\n",
       " 'rep_L1_wins',\n",
       " 'rep_L5_wins',\n",
       " 'rep_L4_wins',\n",
       " 'rep_L3_wins',\n",
       " 'rep_L2_wins',\n",
       " 'dem_L1_wins',\n",
       " 'dem_L5_wins',\n",
       " 'dem_L4_wins',\n",
       " 'dem_L3_wins',\n",
       " 'dem_L2_wins',\n",
       " 'rep_L1_voteshare',\n",
       " 'rep_L5_voteshare',\n",
       " 'rep_L4_voteshare',\n",
       " 'rep_L3_voteshare',\n",
       " 'rep_L2_voteshare',\n",
       " 'dem_L1_voteshare',\n",
       " 'dem_L5_voteshare',\n",
       " 'dem_L4_voteshare',\n",
       " 'dem_L3_voteshare',\n",
       " 'dem_L2_voteshare',\n",
       " 'target',\n",
       " 'dem_incumbent_in_race',\n",
       " 'rep_incumbent_in_race',\n",
       " 'flipped',\n",
       " 'dmargin_45_55',\n",
       " 'mpop_share',\n",
       " 'fpop_share',\n",
       " 'm18_below_share',\n",
       " 'f18_below_share',\n",
       " '18_below_share',\n",
       " 'm18_above_share',\n",
       " 'f18_above_share',\n",
       " '18_above_share',\n",
       " 'm18_29_share',\n",
       " 'f18_29_share',\n",
       " '18_29_share',\n",
       " 'm30_44_share',\n",
       " 'f30_44_share',\n",
       " '30_44_share',\n",
       " 'm45_59_share',\n",
       " 'f45_59_share',\n",
       " '45_59_share',\n",
       " 'm60_74_share',\n",
       " 'f60_74_share',\n",
       " '60_74_share',\n",
       " 'm75_above_share',\n",
       " 'f75_above_share',\n",
       " '75_above_share',\n",
       " 'white_share',\n",
       " 'black_share',\n",
       " 'asian_share',\n",
       " 'hispanic_share',\n",
       " 'otherrace_share',\n",
       " 'native_share',\n",
       " 'nativeinstate_share',\n",
       " 'nativeoutofstate_share',\n",
       " 'foreignborn_share',\n",
       " 'hs_below_share',\n",
       " 'hs_share',\n",
       " 'somecollege_share',\n",
       " 'college_share',\n",
       " 'graddeg_share',\n",
       " 'samehouse_share',\n",
       " 'samecounty_share',\n",
       " 'samestate_share',\n",
       " 'diffstate_share',\n",
       " 'liveabroad_share',\n",
       " 'ptransport_share',\n",
       " 'walktowork_share',\n",
       " 'workathome_share',\n",
       " 'inschool_share',\n",
       " 'incollege_share',\n",
       " 'ingradschool_share',\n",
       " 'm_college_share',\n",
       " 'm_graddeg_share',\n",
       " 'm_phd_share',\n",
       " 'f_college_share',\n",
       " 'f_graddeg_share',\n",
       " 'f_phd_share',\n",
       " 'poverty_share',\n",
       " 'hhinc_10k_less_share',\n",
       " 'hhinc_30k_less_share',\n",
       " 'hhinc_50k_less_share',\n",
       " 'hhinc_75k_more_share',\n",
       " 'hhinc_100k_more_share',\n",
       " 'hhinc_125k_more_share',\n",
       " 'hhinc_150k_more_share',\n",
       " 'hhinc_200k_more_share',\n",
       " 'veteran_share',\n",
       " 'lfp_share',\n",
       " 'unemp_rate',\n",
       " 'armedforce_share',\n",
       " 'vacanthousing_share',\n",
       " 'renter_share',\n",
       " 'mortgage_share',\n",
       " 'l1_mpop_share',\n",
       " 'diff1_mpop_share',\n",
       " 'l1_fpop_share',\n",
       " 'diff1_fpop_share',\n",
       " 'l1_m18_below_share',\n",
       " 'diff1_m18_below_share',\n",
       " 'l1_f18_below_share',\n",
       " 'diff1_f18_below_share',\n",
       " 'l1_18_below_share',\n",
       " 'diff1_18_below_share',\n",
       " 'l1_m18_above_share',\n",
       " 'diff1_m18_above_share',\n",
       " 'l1_f18_above_share',\n",
       " 'diff1_f18_above_share',\n",
       " 'l1_18_above_share',\n",
       " 'diff1_18_above_share',\n",
       " 'l1_m18_29_share',\n",
       " 'diff1_m18_29_share',\n",
       " 'l1_f18_29_share',\n",
       " 'diff1_f18_29_share',\n",
       " 'l1_18_29_share',\n",
       " 'diff1_18_29_share',\n",
       " 'l1_m30_44_share',\n",
       " 'diff1_m30_44_share',\n",
       " 'l1_f30_44_share',\n",
       " 'diff1_f30_44_share',\n",
       " 'l1_30_44_share',\n",
       " 'diff1_30_44_share',\n",
       " 'l1_m45_59_share',\n",
       " 'diff1_m45_59_share',\n",
       " 'l1_f45_59_share',\n",
       " 'diff1_f45_59_share',\n",
       " 'l1_45_59_share',\n",
       " 'diff1_45_59_share',\n",
       " 'l1_m60_74_share',\n",
       " 'diff1_m60_74_share',\n",
       " 'l1_f60_74_share',\n",
       " 'diff1_f60_74_share',\n",
       " 'l1_60_74_share',\n",
       " 'diff1_60_74_share',\n",
       " 'l1_m75_above_share',\n",
       " 'diff1_m75_above_share',\n",
       " 'l1_f75_above_share',\n",
       " 'diff1_f75_above_share',\n",
       " 'l1_75_above_share',\n",
       " 'diff1_75_above_share',\n",
       " 'l1_white_share',\n",
       " 'diff1_white_share',\n",
       " 'l1_black_share',\n",
       " 'diff1_black_share',\n",
       " 'l1_asian_share',\n",
       " 'diff1_asian_share',\n",
       " 'l1_hispanic_share',\n",
       " 'diff1_hispanic_share',\n",
       " 'l1_otherrace_share',\n",
       " 'diff1_otherrace_share',\n",
       " 'l1_native_share',\n",
       " 'diff1_native_share',\n",
       " 'l1_nativeinstate_share',\n",
       " 'diff1_nativeinstate_share',\n",
       " 'l1_nativeoutofstate_share',\n",
       " 'diff1_nativeoutofstate_share',\n",
       " 'l1_foreignborn_share',\n",
       " 'diff1_foreignborn_share',\n",
       " 'l1_hs_below_share',\n",
       " 'diff1_hs_below_share',\n",
       " 'l1_hs_share',\n",
       " 'diff1_hs_share',\n",
       " 'l1_somecollege_share',\n",
       " 'diff1_somecollege_share',\n",
       " 'l1_college_share',\n",
       " 'diff1_college_share',\n",
       " 'l1_graddeg_share',\n",
       " 'diff1_graddeg_share',\n",
       " 'l1_samehouse_share',\n",
       " 'diff1_samehouse_share',\n",
       " 'l1_samecounty_share',\n",
       " 'diff1_samecounty_share',\n",
       " 'l1_samestate_share',\n",
       " 'diff1_samestate_share',\n",
       " 'l1_diffstate_share',\n",
       " 'diff1_diffstate_share',\n",
       " 'l1_liveabroad_share',\n",
       " 'diff1_liveabroad_share',\n",
       " 'l1_ptransport_share',\n",
       " 'diff1_ptransport_share',\n",
       " 'l1_walktowork_share',\n",
       " 'diff1_walktowork_share',\n",
       " 'l1_workathome_share',\n",
       " 'diff1_workathome_share',\n",
       " 'l1_inschool_share',\n",
       " 'diff1_inschool_share',\n",
       " 'l1_incollege_share',\n",
       " 'diff1_incollege_share',\n",
       " 'l1_ingradschool_share',\n",
       " 'diff1_ingradschool_share',\n",
       " 'l1_m_college_share',\n",
       " 'diff1_m_college_share',\n",
       " 'l1_m_graddeg_share',\n",
       " 'diff1_m_graddeg_share',\n",
       " 'l1_m_phd_share',\n",
       " 'diff1_m_phd_share',\n",
       " 'l1_f_college_share',\n",
       " 'diff1_f_college_share',\n",
       " 'l1_f_graddeg_share',\n",
       " 'diff1_f_graddeg_share',\n",
       " 'l1_f_phd_share',\n",
       " 'diff1_f_phd_share',\n",
       " 'l1_poverty_share',\n",
       " 'diff1_poverty_share',\n",
       " 'l1_hhinc_10k_less_share',\n",
       " 'diff1_hhinc_10k_less_share',\n",
       " 'l1_hhinc_30k_less_share',\n",
       " 'diff1_hhinc_30k_less_share',\n",
       " 'l1_hhinc_50k_less_share',\n",
       " 'diff1_hhinc_50k_less_share',\n",
       " 'l1_hhinc_75k_more_share',\n",
       " 'diff1_hhinc_75k_more_share',\n",
       " 'l1_hhinc_100k_more_share',\n",
       " 'diff1_hhinc_100k_more_share',\n",
       " 'l1_hhinc_125k_more_share',\n",
       " 'diff1_hhinc_125k_more_share',\n",
       " 'l1_hhinc_150k_more_share',\n",
       " 'diff1_hhinc_150k_more_share',\n",
       " 'l1_hhinc_200k_more_share',\n",
       " 'diff1_hhinc_200k_more_share',\n",
       " 'l1_veteran_share',\n",
       " 'diff1_veteran_share',\n",
       " 'l1_lfp_share',\n",
       " 'diff1_lfp_share',\n",
       " 'l1_unemp_rate',\n",
       " 'diff1_unemp_rate',\n",
       " 'l1_armedforce_share',\n",
       " 'diff1_armedforce_share',\n",
       " 'l1_vacanthousing_share',\n",
       " 'diff1_vacanthousing_share',\n",
       " 'l1_renter_share',\n",
       " 'diff1_renter_share',\n",
       " 'l1_mortgage_share',\n",
       " 'diff1_mortgage_share',\n",
       " 'median_household_income_scaled',\n",
       " 'income_lowest_quintile_scaled',\n",
       " 'income_second_quintile_scaled',\n",
       " 'income_third_quintile_scaled',\n",
       " 'income_fourth_quintile_scaled',\n",
       " 'income_highest_quintile_scaled',\n",
       " 'income_top_5_percent_scaled',\n",
       " 'median_gross_rent_scaled',\n",
       " 'median_monthly_owner_costs_scaled',\n",
       " 'L1_median_household_income_scaled',\n",
       " 'diff1_median_household_income_scaled',\n",
       " 'L1_income_lowest_quintile_scaled',\n",
       " 'diff1_income_lowest_quintile_scaled',\n",
       " 'L1_income_second_quintile_scaled',\n",
       " 'diff1_income_second_quintile_scaled',\n",
       " 'L1_income_third_quintile_scaled',\n",
       " 'diff1_income_third_quintile_scaled',\n",
       " 'L1_income_fourth_quintile_scaled',\n",
       " 'diff1_income_fourth_quintile_scaled',\n",
       " 'L1_income_highest_quintile_scaled',\n",
       " 'diff1_income_highest_quintile_scaled',\n",
       " 'L1_income_top_5_percent_scaled',\n",
       " 'diff1_income_top_5_percent_scaled',\n",
       " 'L1_median_gross_rent_scaled',\n",
       " 'diff1_median_gross_rent_scaled',\n",
       " 'L1_median_monthly_owner_costs_scaled',\n",
       " 'diff1_median_monthly_owner_costs_scaled']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(housevotes_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations for EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1219\n",
       "1      86\n",
       "Name: flipped, dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housevotes_df.flipped.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign IDs to each district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_id_mapping = dict(zip(housevotes_df.district_id_x.unique(), np.arange(1, 436)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "housevotes_df['idx'] = housevotes_df.district_id_x.map(district_id_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "housevotes_df['2014'] = 0\n",
    "housevotes_df.loc[housevotes_df['year_x']==2014, '2014'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "housevotes_df['2016'] = 0\n",
    "housevotes_df.loc[housevotes_df['year_x']==2016, '2016'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "housevotes_df['2018'] = 0\n",
    "housevotes_df.loc[housevotes_df['year_x']==2018, '2018'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yr_district_id</th>\n",
       "      <th>year_x</th>\n",
       "      <th>state</th>\n",
       "      <th>district_id_x</th>\n",
       "      <th>winner_voteshare</th>\n",
       "      <th>total_dem_vote_share</th>\n",
       "      <th>total_rep_vote_share</th>\n",
       "      <th>dL1_winner</th>\n",
       "      <th>dL2_winner</th>\n",
       "      <th>dL3_winner</th>\n",
       "      <th>...</th>\n",
       "      <th>L1_income_top_5_percent_scaled</th>\n",
       "      <th>diff1_income_top_5_percent_scaled</th>\n",
       "      <th>L1_median_gross_rent_scaled</th>\n",
       "      <th>diff1_median_gross_rent_scaled</th>\n",
       "      <th>L1_median_monthly_owner_costs_scaled</th>\n",
       "      <th>diff1_median_monthly_owner_costs_scaled</th>\n",
       "      <th>idx</th>\n",
       "      <th>2014</th>\n",
       "      <th>2016</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-AK-00</td>\n",
       "      <td>2014</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK-00</td>\n",
       "      <td>0.509657</td>\n",
       "      <td>0.409672</td>\n",
       "      <td>0.585763</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111978</td>\n",
       "      <td>-0.092078</td>\n",
       "      <td>0.876998</td>\n",
       "      <td>-0.141715</td>\n",
       "      <td>0.356498</td>\n",
       "      <td>-0.014218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-AK-00</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK-00</td>\n",
       "      <td>0.503209</td>\n",
       "      <td>0.360220</td>\n",
       "      <td>0.606292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.323404</td>\n",
       "      <td>0.829523</td>\n",
       "      <td>-0.205865</td>\n",
       "      <td>0.435842</td>\n",
       "      <td>-0.059753</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-AK-00</td>\n",
       "      <td>2018</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>AK-00</td>\n",
       "      <td>0.530819</td>\n",
       "      <td>0.464971</td>\n",
       "      <td>0.530819</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198030</td>\n",
       "      <td>0.061056</td>\n",
       "      <td>0.640565</td>\n",
       "      <td>-0.171456</td>\n",
       "      <td>0.353170</td>\n",
       "      <td>-0.024959</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-AL-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-01</td>\n",
       "      <td>0.681569</td>\n",
       "      <td>0.317130</td>\n",
       "      <td>0.681569</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.718340</td>\n",
       "      <td>0.007191</td>\n",
       "      <td>-0.613210</td>\n",
       "      <td>-0.051314</td>\n",
       "      <td>-0.900646</td>\n",
       "      <td>-0.041630</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-AL-01</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-01</td>\n",
       "      <td>0.963825</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.963825</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.716424</td>\n",
       "      <td>0.192309</td>\n",
       "      <td>-0.599062</td>\n",
       "      <td>-0.084289</td>\n",
       "      <td>-0.841109</td>\n",
       "      <td>-0.095664</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-AL-01</td>\n",
       "      <td>2018</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-01</td>\n",
       "      <td>0.631563</td>\n",
       "      <td>0.367765</td>\n",
       "      <td>0.631563</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.697448</td>\n",
       "      <td>0.108855</td>\n",
       "      <td>-0.686589</td>\n",
       "      <td>-0.027177</td>\n",
       "      <td>-0.880409</td>\n",
       "      <td>-0.024897</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-AL-02</td>\n",
       "      <td>2014</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-02</td>\n",
       "      <td>0.673425</td>\n",
       "      <td>0.325641</td>\n",
       "      <td>0.673425</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.805814</td>\n",
       "      <td>-0.075982</td>\n",
       "      <td>-0.829596</td>\n",
       "      <td>-0.098375</td>\n",
       "      <td>-1.143065</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016-AL-02</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-02</td>\n",
       "      <td>0.487685</td>\n",
       "      <td>0.405262</td>\n",
       "      <td>0.487685</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.891080</td>\n",
       "      <td>0.279145</td>\n",
       "      <td>-0.906526</td>\n",
       "      <td>-0.051796</td>\n",
       "      <td>-1.104076</td>\n",
       "      <td>-0.006874</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-AL-02</td>\n",
       "      <td>2018</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-02</td>\n",
       "      <td>0.613884</td>\n",
       "      <td>0.384259</td>\n",
       "      <td>0.613884</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.746709</td>\n",
       "      <td>-0.005034</td>\n",
       "      <td>-0.885662</td>\n",
       "      <td>-0.011760</td>\n",
       "      <td>-1.078625</td>\n",
       "      <td>0.017593</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-AL-03</td>\n",
       "      <td>2014</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-03</td>\n",
       "      <td>0.661205</td>\n",
       "      <td>0.337224</td>\n",
       "      <td>0.661205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.772982</td>\n",
       "      <td>0.115409</td>\n",
       "      <td>-0.956162</td>\n",
       "      <td>-0.121227</td>\n",
       "      <td>-1.113031</td>\n",
       "      <td>0.021076</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2016-AL-03</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-03</td>\n",
       "      <td>0.669318</td>\n",
       "      <td>0.329320</td>\n",
       "      <td>0.669318</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.747597</td>\n",
       "      <td>-0.238431</td>\n",
       "      <td>-1.045260</td>\n",
       "      <td>0.101222</td>\n",
       "      <td>-1.079562</td>\n",
       "      <td>-0.083641</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-AL-03</td>\n",
       "      <td>2018</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-03</td>\n",
       "      <td>0.637173</td>\n",
       "      <td>0.362184</td>\n",
       "      <td>0.637173</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.841494</td>\n",
       "      <td>-0.022730</td>\n",
       "      <td>-0.995152</td>\n",
       "      <td>-0.085927</td>\n",
       "      <td>-1.108146</td>\n",
       "      <td>-0.104514</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2014-AL-04</td>\n",
       "      <td>2014</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-04</td>\n",
       "      <td>0.985744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985744</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.883368</td>\n",
       "      <td>-0.097448</td>\n",
       "      <td>-1.393018</td>\n",
       "      <td>0.020725</td>\n",
       "      <td>-1.346868</td>\n",
       "      <td>0.082894</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2016-AL-04</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-04</td>\n",
       "      <td>0.985303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985303</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.997169</td>\n",
       "      <td>0.163493</td>\n",
       "      <td>-1.360224</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>-1.306873</td>\n",
       "      <td>-0.050103</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-AL-04</td>\n",
       "      <td>2018</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-04</td>\n",
       "      <td>0.797748</td>\n",
       "      <td>0.201291</td>\n",
       "      <td>0.797748</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.006611</td>\n",
       "      <td>0.043256</td>\n",
       "      <td>-1.320305</td>\n",
       "      <td>-0.040929</td>\n",
       "      <td>-1.321123</td>\n",
       "      <td>-0.041116</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2014-AL-05</td>\n",
       "      <td>2014</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-05</td>\n",
       "      <td>0.744241</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744241</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379524</td>\n",
       "      <td>0.164630</td>\n",
       "      <td>-1.074562</td>\n",
       "      <td>0.056154</td>\n",
       "      <td>-0.859886</td>\n",
       "      <td>0.027076</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2016-AL-05</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-05</td>\n",
       "      <td>0.666979</td>\n",
       "      <td>0.331578</td>\n",
       "      <td>0.666979</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194071</td>\n",
       "      <td>-0.145536</td>\n",
       "      <td>-1.079006</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>-0.834423</td>\n",
       "      <td>-0.047919</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-AL-05</td>\n",
       "      <td>2018</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-05</td>\n",
       "      <td>0.610201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.610201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.258347</td>\n",
       "      <td>-0.272291</td>\n",
       "      <td>-0.968609</td>\n",
       "      <td>-0.031536</td>\n",
       "      <td>-0.825583</td>\n",
       "      <td>-0.046938</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-AL-06</td>\n",
       "      <td>2014</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-06</td>\n",
       "      <td>0.761814</td>\n",
       "      <td>0.236992</td>\n",
       "      <td>0.761814</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.429643</td>\n",
       "      <td>0.049593</td>\n",
       "      <td>-0.217182</td>\n",
       "      <td>0.004843</td>\n",
       "      <td>-0.529510</td>\n",
       "      <td>0.127864</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2016-AL-06</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-06</td>\n",
       "      <td>0.744939</td>\n",
       "      <td>0.254198</td>\n",
       "      <td>0.744939</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.275281</td>\n",
       "      <td>-0.231605</td>\n",
       "      <td>-0.105353</td>\n",
       "      <td>-0.455572</td>\n",
       "      <td>-0.019631</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-AL-06</td>\n",
       "      <td>2018</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-06</td>\n",
       "      <td>0.691781</td>\n",
       "      <td>0.307709</td>\n",
       "      <td>0.691781</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618325</td>\n",
       "      <td>-0.365542</td>\n",
       "      <td>-0.384661</td>\n",
       "      <td>0.137820</td>\n",
       "      <td>-0.471324</td>\n",
       "      <td>-0.022126</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-AL-07</td>\n",
       "      <td>2014</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-07</td>\n",
       "      <td>0.983723</td>\n",
       "      <td>0.983723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.109415</td>\n",
       "      <td>-0.022218</td>\n",
       "      <td>-1.013321</td>\n",
       "      <td>0.014573</td>\n",
       "      <td>-1.125903</td>\n",
       "      <td>0.013841</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2016-AL-07</td>\n",
       "      <td>2016</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-07</td>\n",
       "      <td>0.984131</td>\n",
       "      <td>0.984131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.093343</td>\n",
       "      <td>-0.096162</td>\n",
       "      <td>-0.929024</td>\n",
       "      <td>-0.086435</td>\n",
       "      <td>-1.092934</td>\n",
       "      <td>0.053832</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-AL-07</td>\n",
       "      <td>2018</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>AL-07</td>\n",
       "      <td>0.978045</td>\n",
       "      <td>0.978045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.079737</td>\n",
       "      <td>-0.173484</td>\n",
       "      <td>-0.968609</td>\n",
       "      <td>-0.012860</td>\n",
       "      <td>-1.129233</td>\n",
       "      <td>-0.003515</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014-AR-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR-01</td>\n",
       "      <td>0.632536</td>\n",
       "      <td>0.323837</td>\n",
       "      <td>0.676163</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.024163</td>\n",
       "      <td>-0.067031</td>\n",
       "      <td>-1.258286</td>\n",
       "      <td>-0.051093</td>\n",
       "      <td>-1.376903</td>\n",
       "      <td>0.068248</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2016-AR-01</td>\n",
       "      <td>2016</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR-01</td>\n",
       "      <td>0.762781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.001143</td>\n",
       "      <td>-0.041904</td>\n",
       "      <td>-1.266485</td>\n",
       "      <td>-0.023946</td>\n",
       "      <td>-1.262302</td>\n",
       "      <td>-0.035889</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-AR-01</td>\n",
       "      <td>2018</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR-01</td>\n",
       "      <td>0.689493</td>\n",
       "      <td>0.287744</td>\n",
       "      <td>0.712256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.022089</td>\n",
       "      <td>0.091714</td>\n",
       "      <td>-1.260583</td>\n",
       "      <td>0.017637</td>\n",
       "      <td>-1.413905</td>\n",
       "      <td>0.076254</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014-AR-02</td>\n",
       "      <td>2014</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR-02</td>\n",
       "      <td>0.518573</td>\n",
       "      <td>0.436005</td>\n",
       "      <td>0.563195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.507657</td>\n",
       "      <td>0.127131</td>\n",
       "      <td>-0.821431</td>\n",
       "      <td>0.078266</td>\n",
       "      <td>-0.810544</td>\n",
       "      <td>-0.026734</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2016-AR-02</td>\n",
       "      <td>2016</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR-02</td>\n",
       "      <td>0.583448</td>\n",
       "      <td>0.368133</td>\n",
       "      <td>0.630865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341726</td>\n",
       "      <td>0.055743</td>\n",
       "      <td>-0.771542</td>\n",
       "      <td>0.088191</td>\n",
       "      <td>-0.758653</td>\n",
       "      <td>-0.060550</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-AR-02</td>\n",
       "      <td>2018</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>AR-02</td>\n",
       "      <td>0.521300</td>\n",
       "      <td>0.458211</td>\n",
       "      <td>0.541789</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283129</td>\n",
       "      <td>-0.033402</td>\n",
       "      <td>-0.759582</td>\n",
       "      <td>-0.010214</td>\n",
       "      <td>-0.764431</td>\n",
       "      <td>-0.036374</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>2016-OR-05</td>\n",
       "      <td>2016</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>OR-05</td>\n",
       "      <td>0.534711</td>\n",
       "      <td>0.534711</td>\n",
       "      <td>0.430018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.220042</td>\n",
       "      <td>0.078871</td>\n",
       "      <td>-0.306596</td>\n",
       "      <td>0.101768</td>\n",
       "      <td>0.036934</td>\n",
       "      <td>-0.002668</td>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>2018-OR-05</td>\n",
       "      <td>2018</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>OR-05</td>\n",
       "      <td>0.550081</td>\n",
       "      <td>0.550081</td>\n",
       "      <td>0.435019</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043095</td>\n",
       "      <td>0.021158</td>\n",
       "      <td>-0.112595</td>\n",
       "      <td>0.155246</td>\n",
       "      <td>0.100129</td>\n",
       "      <td>0.060063</td>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>2014-PA-01</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-01</td>\n",
       "      <td>0.828371</td>\n",
       "      <td>0.828371</td>\n",
       "      <td>0.171629</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.346933</td>\n",
       "      <td>-0.063636</td>\n",
       "      <td>-0.057955</td>\n",
       "      <td>0.054014</td>\n",
       "      <td>-0.662518</td>\n",
       "      <td>0.111194</td>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>2016-PA-01</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-01</td>\n",
       "      <td>0.822016</td>\n",
       "      <td>0.822016</td>\n",
       "      <td>0.177984</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.302598</td>\n",
       "      <td>-0.088177</td>\n",
       "      <td>-0.040377</td>\n",
       "      <td>0.056954</td>\n",
       "      <td>-0.446658</td>\n",
       "      <td>-0.022013</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>2018-PA-01</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-01</td>\n",
       "      <td>0.512596</td>\n",
       "      <td>0.487404</td>\n",
       "      <td>0.512596</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.410923</td>\n",
       "      <td>0.124365</td>\n",
       "      <td>-0.122549</td>\n",
       "      <td>-0.124293</td>\n",
       "      <td>-0.568324</td>\n",
       "      <td>-0.017333</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>2014-PA-02</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-02</td>\n",
       "      <td>0.877035</td>\n",
       "      <td>0.877035</td>\n",
       "      <td>0.122965</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011932</td>\n",
       "      <td>-0.003171</td>\n",
       "      <td>-0.115113</td>\n",
       "      <td>0.016803</td>\n",
       "      <td>-0.724732</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>326</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>2016-PA-02</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-02</td>\n",
       "      <td>0.901771</td>\n",
       "      <td>0.901771</td>\n",
       "      <td>0.098229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.042892</td>\n",
       "      <td>-0.341177</td>\n",
       "      <td>-0.152864</td>\n",
       "      <td>-0.044823</td>\n",
       "      <td>-0.613798</td>\n",
       "      <td>-0.020341</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>2018-PA-02</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-02</td>\n",
       "      <td>0.790169</td>\n",
       "      <td>0.790169</td>\n",
       "      <td>0.209831</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.482730</td>\n",
       "      <td>0.245812</td>\n",
       "      <td>-0.109277</td>\n",
       "      <td>-0.100210</td>\n",
       "      <td>-0.737018</td>\n",
       "      <td>0.175950</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>2014-PA-03</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-03</td>\n",
       "      <td>0.606310</td>\n",
       "      <td>0.393690</td>\n",
       "      <td>0.606310</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.612388</td>\n",
       "      <td>0.123097</td>\n",
       "      <td>-1.156217</td>\n",
       "      <td>0.086692</td>\n",
       "      <td>-0.934971</td>\n",
       "      <td>-0.038581</td>\n",
       "      <td>327</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>2016-PA-03</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.547149</td>\n",
       "      <td>-0.082892</td>\n",
       "      <td>-1.071507</td>\n",
       "      <td>-0.029657</td>\n",
       "      <td>-0.985964</td>\n",
       "      <td>0.070963</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>2018-PA-03</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-03</td>\n",
       "      <td>0.933808</td>\n",
       "      <td>0.933808</td>\n",
       "      <td>0.066192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.536929</td>\n",
       "      <td>-0.006316</td>\n",
       "      <td>-1.074781</td>\n",
       "      <td>-0.059216</td>\n",
       "      <td>-0.947887</td>\n",
       "      <td>0.022091</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>2014-PA-04</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-04</td>\n",
       "      <td>0.745363</td>\n",
       "      <td>0.254637</td>\n",
       "      <td>0.745363</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>0.011198</td>\n",
       "      <td>-0.494810</td>\n",
       "      <td>0.144849</td>\n",
       "      <td>-0.089724</td>\n",
       "      <td>-0.097457</td>\n",
       "      <td>328</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>2016-PA-04</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-04</td>\n",
       "      <td>0.660563</td>\n",
       "      <td>0.339437</td>\n",
       "      <td>0.660563</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132429</td>\n",
       "      <td>-0.407398</td>\n",
       "      <td>-0.385337</td>\n",
       "      <td>0.034095</td>\n",
       "      <td>-0.159177</td>\n",
       "      <td>-0.050405</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>2018-PA-04</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-04</td>\n",
       "      <td>0.635224</td>\n",
       "      <td>0.635224</td>\n",
       "      <td>0.364776</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.620160</td>\n",
       "      <td>0.259421</td>\n",
       "      <td>-0.384661</td>\n",
       "      <td>-0.002257</td>\n",
       "      <td>-0.155022</td>\n",
       "      <td>-0.031073</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>2014-PA-05</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-05</td>\n",
       "      <td>0.635961</td>\n",
       "      <td>0.364039</td>\n",
       "      <td>0.635961</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605942</td>\n",
       "      <td>-0.251193</td>\n",
       "      <td>-0.988824</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>-1.113031</td>\n",
       "      <td>-0.005732</td>\n",
       "      <td>329</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>2016-PA-05</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-05</td>\n",
       "      <td>0.671644</td>\n",
       "      <td>0.328356</td>\n",
       "      <td>0.671644</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.866473</td>\n",
       "      <td>0.104438</td>\n",
       "      <td>-0.936523</td>\n",
       "      <td>-0.043226</td>\n",
       "      <td>-1.133047</td>\n",
       "      <td>0.026451</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>2018-PA-05</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-05</td>\n",
       "      <td>0.651887</td>\n",
       "      <td>0.651887</td>\n",
       "      <td>0.348113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.657207</td>\n",
       "      <td>-0.257875</td>\n",
       "      <td>-0.971927</td>\n",
       "      <td>-0.062460</td>\n",
       "      <td>-1.095494</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>2014-PA-06</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-06</td>\n",
       "      <td>0.562909</td>\n",
       "      <td>0.437091</td>\n",
       "      <td>0.562909</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794744</td>\n",
       "      <td>0.180262</td>\n",
       "      <td>0.542211</td>\n",
       "      <td>-0.062511</td>\n",
       "      <td>0.592481</td>\n",
       "      <td>-0.013396</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>2016-PA-06</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-06</td>\n",
       "      <td>0.572377</td>\n",
       "      <td>0.427623</td>\n",
       "      <td>0.572377</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906841</td>\n",
       "      <td>0.042595</td>\n",
       "      <td>0.510810</td>\n",
       "      <td>0.030714</td>\n",
       "      <td>0.643096</td>\n",
       "      <td>-0.129842</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>2018-PA-06</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-06</td>\n",
       "      <td>0.588759</td>\n",
       "      <td>0.588759</td>\n",
       "      <td>0.411241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.218683</td>\n",
       "      <td>-0.186850</td>\n",
       "      <td>0.375134</td>\n",
       "      <td>-0.133262</td>\n",
       "      <td>0.513430</td>\n",
       "      <td>-0.058179</td>\n",
       "      <td>330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>2014-PA-07</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-07</td>\n",
       "      <td>0.620389</td>\n",
       "      <td>0.379611</td>\n",
       "      <td>0.620389</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.539028</td>\n",
       "      <td>-0.074497</td>\n",
       "      <td>0.521797</td>\n",
       "      <td>0.193826</td>\n",
       "      <td>0.779122</td>\n",
       "      <td>0.059109</td>\n",
       "      <td>331</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>2016-PA-07</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-07</td>\n",
       "      <td>0.594669</td>\n",
       "      <td>0.405331</td>\n",
       "      <td>0.594669</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.228132</td>\n",
       "      <td>-0.040275</td>\n",
       "      <td>0.495811</td>\n",
       "      <td>0.113563</td>\n",
       "      <td>0.828065</td>\n",
       "      <td>-0.055722</td>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>2018-PA-07</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-07</td>\n",
       "      <td>0.534880</td>\n",
       "      <td>0.534880</td>\n",
       "      <td>0.465120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.321536</td>\n",
       "      <td>0.157248</td>\n",
       "      <td>0.584161</td>\n",
       "      <td>-0.280032</td>\n",
       "      <td>0.749603</td>\n",
       "      <td>-0.042320</td>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>2014-PA-08</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-08</td>\n",
       "      <td>0.619021</td>\n",
       "      <td>0.380979</td>\n",
       "      <td>0.619021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701554</td>\n",
       "      <td>0.203062</td>\n",
       "      <td>0.672860</td>\n",
       "      <td>-0.086994</td>\n",
       "      <td>0.873515</td>\n",
       "      <td>-0.006242</td>\n",
       "      <td>332</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>2016-PA-08</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-08</td>\n",
       "      <td>0.544257</td>\n",
       "      <td>0.455743</td>\n",
       "      <td>0.544257</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877483</td>\n",
       "      <td>0.025588</td>\n",
       "      <td>0.615797</td>\n",
       "      <td>0.047142</td>\n",
       "      <td>0.877093</td>\n",
       "      <td>0.054187</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2018-PA-08</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-08</td>\n",
       "      <td>0.546421</td>\n",
       "      <td>0.546421</td>\n",
       "      <td>0.453579</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001921</td>\n",
       "      <td>-0.344677</td>\n",
       "      <td>0.418266</td>\n",
       "      <td>-0.030091</td>\n",
       "      <td>0.836059</td>\n",
       "      <td>-0.048864</td>\n",
       "      <td>332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2014-PA-09</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-09</td>\n",
       "      <td>0.635218</td>\n",
       "      <td>0.364782</td>\n",
       "      <td>0.635218</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.991252</td>\n",
       "      <td>-0.006277</td>\n",
       "      <td>-1.094976</td>\n",
       "      <td>-0.096442</td>\n",
       "      <td>-1.200988</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2016-PA-09</td>\n",
       "      <td>2016</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-09</td>\n",
       "      <td>0.633409</td>\n",
       "      <td>0.366591</td>\n",
       "      <td>0.633409</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.006976</td>\n",
       "      <td>0.104950</td>\n",
       "      <td>-1.101504</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>-1.146418</td>\n",
       "      <td>0.083367</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2018-PA-09</td>\n",
       "      <td>2018</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-09</td>\n",
       "      <td>0.597456</td>\n",
       "      <td>0.402544</td>\n",
       "      <td>0.597456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.893867</td>\n",
       "      <td>0.003941</td>\n",
       "      <td>-1.098006</td>\n",
       "      <td>-0.020426</td>\n",
       "      <td>-1.076516</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>2014-PA-10</td>\n",
       "      <td>2014</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>PA-10</td>\n",
       "      <td>0.625830</td>\n",
       "      <td>0.248095</td>\n",
       "      <td>0.625830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.767026</td>\n",
       "      <td>0.064128</td>\n",
       "      <td>-0.894921</td>\n",
       "      <td>0.128163</td>\n",
       "      <td>-0.782655</td>\n",
       "      <td>0.079418</td>\n",
       "      <td>334</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yr_district_id  year_x         state district_id_x  winner_voteshare  \\\n",
       "0       2014-AK-00    2014        Alaska         AK-00          0.509657   \n",
       "1       2016-AK-00    2016        Alaska         AK-00          0.503209   \n",
       "2       2018-AK-00    2018        Alaska         AK-00          0.530819   \n",
       "3       2014-AL-01    2014       Alabama         AL-01          0.681569   \n",
       "4       2016-AL-01    2016       Alabama         AL-01          0.963825   \n",
       "5       2018-AL-01    2018       Alabama         AL-01          0.631563   \n",
       "6       2014-AL-02    2014       Alabama         AL-02          0.673425   \n",
       "7       2016-AL-02    2016       Alabama         AL-02          0.487685   \n",
       "8       2018-AL-02    2018       Alabama         AL-02          0.613884   \n",
       "9       2014-AL-03    2014       Alabama         AL-03          0.661205   \n",
       "10      2016-AL-03    2016       Alabama         AL-03          0.669318   \n",
       "11      2018-AL-03    2018       Alabama         AL-03          0.637173   \n",
       "12      2014-AL-04    2014       Alabama         AL-04          0.985744   \n",
       "13      2016-AL-04    2016       Alabama         AL-04          0.985303   \n",
       "14      2018-AL-04    2018       Alabama         AL-04          0.797748   \n",
       "15      2014-AL-05    2014       Alabama         AL-05          0.744241   \n",
       "16      2016-AL-05    2016       Alabama         AL-05          0.666979   \n",
       "17      2018-AL-05    2018       Alabama         AL-05          0.610201   \n",
       "18      2014-AL-06    2014       Alabama         AL-06          0.761814   \n",
       "19      2016-AL-06    2016       Alabama         AL-06          0.744939   \n",
       "20      2018-AL-06    2018       Alabama         AL-06          0.691781   \n",
       "21      2014-AL-07    2014       Alabama         AL-07          0.983723   \n",
       "22      2016-AL-07    2016       Alabama         AL-07          0.984131   \n",
       "23      2018-AL-07    2018       Alabama         AL-07          0.978045   \n",
       "24      2014-AR-01    2014      Arkansas         AR-01          0.632536   \n",
       "25      2016-AR-01    2016      Arkansas         AR-01          0.762781   \n",
       "26      2018-AR-01    2018      Arkansas         AR-01          0.689493   \n",
       "27      2014-AR-02    2014      Arkansas         AR-02          0.518573   \n",
       "28      2016-AR-02    2016      Arkansas         AR-02          0.583448   \n",
       "29      2018-AR-02    2018      Arkansas         AR-02          0.521300   \n",
       "..             ...     ...           ...           ...               ...   \n",
       "970     2016-OR-05    2016        Oregon         OR-05          0.534711   \n",
       "971     2018-OR-05    2018        Oregon         OR-05          0.550081   \n",
       "972     2014-PA-01    2014  Pennsylvania         PA-01          0.828371   \n",
       "973     2016-PA-01    2016  Pennsylvania         PA-01          0.822016   \n",
       "974     2018-PA-01    2018  Pennsylvania         PA-01          0.512596   \n",
       "975     2014-PA-02    2014  Pennsylvania         PA-02          0.877035   \n",
       "976     2016-PA-02    2016  Pennsylvania         PA-02          0.901771   \n",
       "977     2018-PA-02    2018  Pennsylvania         PA-02          0.790169   \n",
       "978     2014-PA-03    2014  Pennsylvania         PA-03          0.606310   \n",
       "979     2016-PA-03    2016  Pennsylvania         PA-03          1.000000   \n",
       "980     2018-PA-03    2018  Pennsylvania         PA-03          0.933808   \n",
       "981     2014-PA-04    2014  Pennsylvania         PA-04          0.745363   \n",
       "982     2016-PA-04    2016  Pennsylvania         PA-04          0.660563   \n",
       "983     2018-PA-04    2018  Pennsylvania         PA-04          0.635224   \n",
       "984     2014-PA-05    2014  Pennsylvania         PA-05          0.635961   \n",
       "985     2016-PA-05    2016  Pennsylvania         PA-05          0.671644   \n",
       "986     2018-PA-05    2018  Pennsylvania         PA-05          0.651887   \n",
       "987     2014-PA-06    2014  Pennsylvania         PA-06          0.562909   \n",
       "988     2016-PA-06    2016  Pennsylvania         PA-06          0.572377   \n",
       "989     2018-PA-06    2018  Pennsylvania         PA-06          0.588759   \n",
       "990     2014-PA-07    2014  Pennsylvania         PA-07          0.620389   \n",
       "991     2016-PA-07    2016  Pennsylvania         PA-07          0.594669   \n",
       "992     2018-PA-07    2018  Pennsylvania         PA-07          0.534880   \n",
       "993     2014-PA-08    2014  Pennsylvania         PA-08          0.619021   \n",
       "994     2016-PA-08    2016  Pennsylvania         PA-08          0.544257   \n",
       "995     2018-PA-08    2018  Pennsylvania         PA-08          0.546421   \n",
       "996     2014-PA-09    2014  Pennsylvania         PA-09          0.635218   \n",
       "997     2016-PA-09    2016  Pennsylvania         PA-09          0.633409   \n",
       "998     2018-PA-09    2018  Pennsylvania         PA-09          0.597456   \n",
       "999     2014-PA-10    2014  Pennsylvania         PA-10          0.625830   \n",
       "\n",
       "     total_dem_vote_share  total_rep_vote_share  dL1_winner  dL2_winner  \\\n",
       "0                0.409672              0.585763           1           1   \n",
       "1                0.360220              0.606292           1           1   \n",
       "2                0.464971              0.530819           1           1   \n",
       "3                0.317130              0.681569           0           0   \n",
       "4                0.000000              0.963825           1           0   \n",
       "5                0.367765              0.631563           1           1   \n",
       "6                0.325641              0.673425           1           1   \n",
       "7                0.405262              0.487685           1           1   \n",
       "8                0.384259              0.613884           1           1   \n",
       "9                0.337224              0.661205           1           1   \n",
       "10               0.329320              0.669318           1           1   \n",
       "11               0.362184              0.637173           1           1   \n",
       "12               0.000000              0.985744           1           1   \n",
       "13               0.000000              0.985303           1           1   \n",
       "14               0.201291              0.797748           1           1   \n",
       "15               0.000000              0.744241           1           1   \n",
       "16               0.331578              0.666979           1           1   \n",
       "17               0.000000              0.610201           1           1   \n",
       "18               0.236992              0.761814           0           0   \n",
       "19               0.254198              0.744939           1           0   \n",
       "20               0.307709              0.691781           1           1   \n",
       "21               0.983723              0.000000           1           1   \n",
       "22               0.984131              0.000000           1           1   \n",
       "23               0.978045              0.000000           1           1   \n",
       "24               0.323837              0.676163           1           1   \n",
       "25               0.000000              1.000000           1           1   \n",
       "26               0.287744              0.712256           1           1   \n",
       "27               0.436005              0.563195           0           0   \n",
       "28               0.368133              0.630865           1           0   \n",
       "29               0.458211              0.541789           1           1   \n",
       "..                    ...                   ...         ...         ...   \n",
       "970              0.534711              0.430018           1           1   \n",
       "971              0.550081              0.435019           1           1   \n",
       "972              0.828371              0.171629           1           1   \n",
       "973              0.822016              0.177984           1           1   \n",
       "974              0.487404              0.512596           0           0   \n",
       "975              0.877035              0.122965           1           1   \n",
       "976              0.901771              0.098229           0           0   \n",
       "977              0.790169              0.209831           0           0   \n",
       "978              0.393690              0.606310           1           1   \n",
       "979              0.000000              1.000000           1           1   \n",
       "980              0.933808              0.066192           0           0   \n",
       "981              0.254637              0.745363           1           0   \n",
       "982              0.339437              0.660563           1           1   \n",
       "983              0.635224              0.364776           0           0   \n",
       "984              0.364039              0.635961           1           1   \n",
       "985              0.328356              0.671644           1           1   \n",
       "986              0.651887              0.348113           0           0   \n",
       "987              0.437091              0.562909           0           0   \n",
       "988              0.427623              0.572377           1           0   \n",
       "989              0.588759              0.411241           0           0   \n",
       "990              0.379611              0.620389           1           1   \n",
       "991              0.405331              0.594669           1           1   \n",
       "992              0.534880              0.465120           0           0   \n",
       "993              0.380979              0.619021           1           1   \n",
       "994              0.455743              0.544257           0           0   \n",
       "995              0.546421              0.453579           0           0   \n",
       "996              0.364782              0.635218           1           1   \n",
       "997              0.366591              0.633409           1           1   \n",
       "998              0.402544              0.597456           0           0   \n",
       "999              0.248095              0.625830           1           1   \n",
       "\n",
       "     dL3_winner  ...  L1_income_top_5_percent_scaled  \\\n",
       "0             1  ...                        0.111978   \n",
       "1             1  ...                        0.023688   \n",
       "2             1  ...                       -0.198030   \n",
       "3             0  ...                       -0.718340   \n",
       "4             0  ...                       -0.716424   \n",
       "5             0  ...                       -0.697448   \n",
       "6             0  ...                       -0.805814   \n",
       "7             1  ...                       -0.891080   \n",
       "8             1  ...                       -0.746709   \n",
       "9             1  ...                       -0.772982   \n",
       "10            1  ...                       -0.747597   \n",
       "11            1  ...                       -0.841494   \n",
       "12            1  ...                       -0.883368   \n",
       "13            1  ...                       -0.997169   \n",
       "14            1  ...                       -1.006611   \n",
       "15            0  ...                       -0.379524   \n",
       "16            1  ...                       -0.194071   \n",
       "17            1  ...                       -0.258347   \n",
       "18            0  ...                        0.429643   \n",
       "19            0  ...                        0.008237   \n",
       "20            0  ...                        0.618325   \n",
       "21            0  ...                       -1.109415   \n",
       "22            1  ...                       -1.093343   \n",
       "23            1  ...                       -1.079737   \n",
       "24            0  ...                       -1.024163   \n",
       "25            1  ...                       -1.001143   \n",
       "26            1  ...                       -1.022089   \n",
       "27            0  ...                       -0.507657   \n",
       "28            0  ...                       -0.341726   \n",
       "29            0  ...                       -0.283129   \n",
       "..          ...  ...                             ...   \n",
       "970           1  ...                       -0.220042   \n",
       "971           1  ...                        0.043095   \n",
       "972           1  ...                       -0.346933   \n",
       "973           1  ...                       -0.302598   \n",
       "974           0  ...                       -0.410923   \n",
       "975           1  ...                        1.011932   \n",
       "976           0  ...                        1.042892   \n",
       "977           0  ...                        0.482730   \n",
       "978           0  ...                       -0.612388   \n",
       "979           1  ...                       -0.547149   \n",
       "980           0  ...                       -0.536929   \n",
       "981           0  ...                       -0.425598   \n",
       "982           0  ...                       -0.132429   \n",
       "983           0  ...                       -0.620160   \n",
       "984           1  ...                       -0.605942   \n",
       "985           1  ...                       -0.866473   \n",
       "986           0  ...                       -0.657207   \n",
       "987           0  ...                        0.794744   \n",
       "988           0  ...                        0.906841   \n",
       "989           0  ...                        1.218683   \n",
       "990           0  ...                        1.539028   \n",
       "991           1  ...                        1.228132   \n",
       "992           0  ...                        1.321536   \n",
       "993           0  ...                        0.701554   \n",
       "994           0  ...                        0.877483   \n",
       "995           0  ...                        1.001921   \n",
       "996           1  ...                       -0.991252   \n",
       "997           1  ...                       -1.006976   \n",
       "998           0  ...                       -0.893867   \n",
       "999           0  ...                       -0.767026   \n",
       "\n",
       "     diff1_income_top_5_percent_scaled  L1_median_gross_rent_scaled  \\\n",
       "0                            -0.092078                     0.876998   \n",
       "1                             0.323404                     0.829523   \n",
       "2                             0.061056                     0.640565   \n",
       "3                             0.007191                    -0.613210   \n",
       "4                             0.192309                    -0.599062   \n",
       "5                             0.108855                    -0.686589   \n",
       "6                            -0.075982                    -0.829596   \n",
       "7                             0.279145                    -0.906526   \n",
       "8                            -0.005034                    -0.885662   \n",
       "9                             0.115409                    -0.956162   \n",
       "10                           -0.238431                    -1.045260   \n",
       "11                           -0.022730                    -0.995152   \n",
       "12                           -0.097448                    -1.393018   \n",
       "13                            0.163493                    -1.360224   \n",
       "14                            0.043256                    -1.320305   \n",
       "15                            0.164630                    -1.074562   \n",
       "16                           -0.145536                    -1.079006   \n",
       "17                           -0.272291                    -0.968609   \n",
       "18                            0.049593                    -0.217182   \n",
       "19                            0.275281                    -0.231605   \n",
       "20                           -0.365542                    -0.384661   \n",
       "21                           -0.022218                    -1.013321   \n",
       "22                           -0.096162                    -0.929024   \n",
       "23                           -0.173484                    -0.968609   \n",
       "24                           -0.067031                    -1.258286   \n",
       "25                           -0.041904                    -1.266485   \n",
       "26                            0.091714                    -1.260583   \n",
       "27                            0.127131                    -0.821431   \n",
       "28                            0.055743                    -0.771542   \n",
       "29                           -0.033402                    -0.759582   \n",
       "..                                 ...                          ...   \n",
       "970                           0.078871                    -0.306596   \n",
       "971                           0.021158                    -0.112595   \n",
       "972                          -0.063636                    -0.057955   \n",
       "973                          -0.088177                    -0.040377   \n",
       "974                           0.124365                    -0.122549   \n",
       "975                          -0.003171                    -0.115113   \n",
       "976                          -0.341177                    -0.152864   \n",
       "977                           0.245812                    -0.109277   \n",
       "978                           0.123097                    -1.156217   \n",
       "979                          -0.082892                    -1.071507   \n",
       "980                          -0.006316                    -1.074781   \n",
       "981                           0.011198                    -0.494810   \n",
       "982                          -0.407398                    -0.385337   \n",
       "983                           0.259421                    -0.384661   \n",
       "984                          -0.251193                    -0.988824   \n",
       "985                           0.104438                    -0.936523   \n",
       "986                          -0.257875                    -0.971927   \n",
       "987                           0.180262                     0.542211   \n",
       "988                           0.042595                     0.510810   \n",
       "989                          -0.186850                     0.375134   \n",
       "990                          -0.074497                     0.521797   \n",
       "991                          -0.040275                     0.495811   \n",
       "992                           0.157248                     0.584161   \n",
       "993                           0.203062                     0.672860   \n",
       "994                           0.025588                     0.615797   \n",
       "995                          -0.344677                     0.418266   \n",
       "996                          -0.006277                    -1.094976   \n",
       "997                           0.104950                    -1.101504   \n",
       "998                           0.003941                    -1.098006   \n",
       "999                           0.064128                    -0.894921   \n",
       "\n",
       "     diff1_median_gross_rent_scaled  L1_median_monthly_owner_costs_scaled  \\\n",
       "0                         -0.141715                              0.356498   \n",
       "1                         -0.205865                              0.435842   \n",
       "2                         -0.171456                              0.353170   \n",
       "3                         -0.051314                             -0.900646   \n",
       "4                         -0.084289                             -0.841109   \n",
       "5                         -0.027177                             -0.880409   \n",
       "6                         -0.098375                             -1.143065   \n",
       "7                         -0.051796                             -1.104076   \n",
       "8                         -0.011760                             -1.078625   \n",
       "9                         -0.121227                             -1.113031   \n",
       "10                         0.101222                             -1.079562   \n",
       "11                        -0.085927                             -1.108146   \n",
       "12                         0.020725                             -1.346868   \n",
       "13                         0.001943                             -1.306873   \n",
       "14                        -0.040929                             -1.321123   \n",
       "15                         0.056154                             -0.859886   \n",
       "16                         0.027837                             -0.834423   \n",
       "17                        -0.031536                             -0.825583   \n",
       "18                         0.004843                             -0.529510   \n",
       "19                        -0.105353                             -0.455572   \n",
       "20                         0.137820                             -0.471324   \n",
       "21                         0.014573                             -1.125903   \n",
       "22                        -0.086435                             -1.092934   \n",
       "23                        -0.012860                             -1.129233   \n",
       "24                        -0.051093                             -1.376903   \n",
       "25                        -0.023946                             -1.262302   \n",
       "26                         0.017637                             -1.413905   \n",
       "27                         0.078266                             -0.810544   \n",
       "28                         0.088191                             -0.758653   \n",
       "29                        -0.010214                             -0.764431   \n",
       "..                              ...                                   ...   \n",
       "970                        0.101768                              0.036934   \n",
       "971                        0.155246                              0.100129   \n",
       "972                        0.054014                             -0.662518   \n",
       "973                        0.056954                             -0.446658   \n",
       "974                       -0.124293                             -0.568324   \n",
       "975                        0.016803                             -0.724732   \n",
       "976                       -0.044823                             -0.613798   \n",
       "977                       -0.100210                             -0.737018   \n",
       "978                        0.086692                             -0.934971   \n",
       "979                       -0.029657                             -0.985964   \n",
       "980                       -0.059216                             -0.947887   \n",
       "981                        0.144849                             -0.089724   \n",
       "982                        0.034095                             -0.159177   \n",
       "983                       -0.002257                             -0.155022   \n",
       "984                       -0.002060                             -1.113031   \n",
       "985                       -0.043226                             -1.133047   \n",
       "986                       -0.062460                             -1.095494   \n",
       "987                       -0.062511                              0.592481   \n",
       "988                        0.030714                              0.643096   \n",
       "989                       -0.133262                              0.513430   \n",
       "990                        0.193826                              0.779122   \n",
       "991                        0.113563                              0.828065   \n",
       "992                       -0.280032                              0.749603   \n",
       "993                       -0.086994                              0.873515   \n",
       "994                        0.047142                              0.877093   \n",
       "995                       -0.030091                              0.836059   \n",
       "996                       -0.096442                             -1.200988   \n",
       "997                        0.018194                             -1.146418   \n",
       "998                       -0.020426                             -1.076516   \n",
       "999                        0.128163                             -0.782655   \n",
       "\n",
       "     diff1_median_monthly_owner_costs_scaled  idx  2014  2016  2018  \n",
       "0                                  -0.014218    1     1     0     0  \n",
       "1                                  -0.059753    1     0     1     0  \n",
       "2                                  -0.024959    1     0     0     1  \n",
       "3                                  -0.041630    2     1     0     0  \n",
       "4                                  -0.095664    2     0     1     0  \n",
       "5                                  -0.024897    2     0     0     1  \n",
       "6                                   0.004196    3     1     0     0  \n",
       "7                                  -0.006874    3     0     1     0  \n",
       "8                                   0.017593    3     0     0     1  \n",
       "9                                   0.021076    4     1     0     0  \n",
       "10                                 -0.083641    4     0     1     0  \n",
       "11                                 -0.104514    4     0     0     1  \n",
       "12                                  0.082894    5     1     0     0  \n",
       "13                                 -0.050103    5     0     1     0  \n",
       "14                                 -0.041116    5     0     0     1  \n",
       "15                                  0.027076    6     1     0     0  \n",
       "16                                 -0.047919    6     0     1     0  \n",
       "17                                 -0.046938    6     0     0     1  \n",
       "18                                  0.127864    7     1     0     0  \n",
       "19                                 -0.019631    7     0     1     0  \n",
       "20                                 -0.022126    7     0     0     1  \n",
       "21                                  0.013841    8     1     0     0  \n",
       "22                                  0.053832    8     0     1     0  \n",
       "23                                 -0.003515    8     0     0     1  \n",
       "24                                  0.068248    9     1     0     0  \n",
       "25                                 -0.035889    9     0     1     0  \n",
       "26                                  0.076254    9     0     0     1  \n",
       "27                                 -0.026734   10     1     0     0  \n",
       "28                                 -0.060550   10     0     1     0  \n",
       "29                                 -0.036374   10     0     0     1  \n",
       "..                                       ...  ...   ...   ...   ...  \n",
       "970                                -0.002668  324     0     1     0  \n",
       "971                                 0.060063  324     0     0     1  \n",
       "972                                 0.111194  325     1     0     0  \n",
       "973                                -0.022013  325     0     1     0  \n",
       "974                                -0.017333  325     0     0     1  \n",
       "975                                 0.010325  326     1     0     0  \n",
       "976                                -0.020341  326     0     1     0  \n",
       "977                                 0.175950  326     0     0     1  \n",
       "978                                -0.038581  327     1     0     0  \n",
       "979                                 0.070963  327     0     1     0  \n",
       "980                                 0.022091  327     0     0     1  \n",
       "981                                -0.097457  328     1     0     0  \n",
       "982                                -0.050405  328     0     1     0  \n",
       "983                                -0.031073  328     0     0     1  \n",
       "984                                -0.005732  329     1     0     0  \n",
       "985                                 0.026451  329     0     1     0  \n",
       "986                                 0.007825  329     0     0     1  \n",
       "987                                -0.013396  330     1     0     0  \n",
       "988                                -0.129842  330     0     1     0  \n",
       "989                                -0.058179  330     0     0     1  \n",
       "990                                 0.059109  331     1     0     0  \n",
       "991                                -0.055722  331     0     1     0  \n",
       "992                                -0.042320  331     0     0     1  \n",
       "993                                -0.006242  332     1     0     0  \n",
       "994                                 0.054187  332     0     1     0  \n",
       "995                                -0.048864  332     0     0     1  \n",
       "996                                 0.048715  333     1     0     0  \n",
       "997                                 0.083367  333     0     1     0  \n",
       "998                                 0.003190  333     0     0     1  \n",
       "999                                 0.079418  334     1     0     0  \n",
       "\n",
       "[1000 rows x 282 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housevotes_df.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a custom train-test-split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def district_train_test_split(dataframe, idx_colname, np_seed, tts_seed, test_size, cols_for_stratify):\n",
    "    \"\"\"\n",
    "    Split a dataframe containing numeric IDs for each congressional district\n",
    "    into train and test sets, such that there is no leakage of districts between\n",
    "    the train and test sets.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "        dataframe : a dataframe with a column for district-level numeric ID\n",
    "        idx_colname : the name of the column containing the district numberic ID (string)\n",
    "        np_seed : the random seed for Numpy, for splitting the districts into 2 samples\n",
    "        tts_seed : the random state seed to be passed into train_test_split()\n",
    "        test_size : the test size to be passed into train_test_split()\n",
    "        cols_for_stratify : list of column names to pass to the stratify parameter\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "        X_train, X_test, y_train, y_test (also prints a report on their shapes)\n",
    "        \n",
    "    \"\"\"\n",
    "    np.random.seed(np_seed)\n",
    "    population = np.arange(1, 436)\n",
    "    sample_1_ids = np.random.choice(population, 200, replace=False)\n",
    "    sample_2_ids = list(set(population) - set(sample_1_ids))\n",
    "    sample_1 = dataframe[dataframe[idx_colname].isin(sample_1_ids)]\n",
    "    sample_2 = dataframe[dataframe[idx_colname].isin(sample_2_ids)]\n",
    "    train_s1, test_s1 = train_test_split(sample_1, \n",
    "                                         test_size=test_size, \n",
    "                                         random_state=tts_seed, \n",
    "                                         stratify=sample_1[cols_for_stratify]\n",
    "                                        )\n",
    "    train_s2, test_s2 = train_test_split(sample_2,\n",
    "                                         test_size=test_size,\n",
    "                                         random_state=tts_seed, \n",
    "                                         stratify=sample_2[cols_for_stratify]\n",
    "                                        )\n",
    "    train = pd.concat([train_s1, train_s2], axis=0)\n",
    "    test = pd.concat([test_s1, test_s2], axis=0)\n",
    "#     X_train = train.drop(['target', 'idx'], axis=True)\n",
    "#     y_train = train['target']\n",
    "#     X_test = test.drop(['target', 'idx'], axis=True)\n",
    "#     y_test = test['target']\n",
    "\n",
    "#     print('Shape for X_train:', X_train.shape)\n",
    "#     print('Shape for y_train:', y_train.shape)\n",
    "#     print('Shape for X_test:', X_test.shape)\n",
    "#     print('Shape for y_test:', y_test.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old tests to try on our custom TTS function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(train_s1.idx.unique()) == set(train_s2.idx.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set = set(list(set(train.idx.unique())) + [1000, 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(train.idx.unique()) - set(train_s1.idx.unique()) - set(train_s2.idx.unique())  # looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set - set(train_s1.idx.unique()) - set(train_s2.idx.unique())  # looks good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['yr_district_id', 'year_x', 'state', 'district_id_x',\n",
       "       'winner_voteshare', 'total_dem_vote_share', 'total_rep_vote_share',\n",
       "       'dL1_winner', 'dL2_winner', 'dL3_winner',\n",
       "       ...\n",
       "       'diff1_income_fourth_quintile_scaled',\n",
       "       'L1_income_highest_quintile_scaled',\n",
       "       'diff1_income_highest_quintile_scaled',\n",
       "       'L1_income_top_5_percent_scaled', 'diff1_income_top_5_percent_scaled',\n",
       "       'L1_median_gross_rent_scaled', 'diff1_median_gross_rent_scaled',\n",
       "       'L1_median_monthly_owner_costs_scaled',\n",
       "       'diff1_median_monthly_owner_costs_scaled', 'idx'],\n",
       "      dtype='object', length=279)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housevotes_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different strategies for train test split\n",
    "\n",
    "A. Split train/test by year (*)\n",
    " - As long as there is no variable (explicit or implicit) in the training set that tracks with the district, we should be okay splitting train/test on year\n",
    " \n",
    "\n",
    "B. Split train test by district level (so that a districts either appears in train or test but not both)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy A: Train test split by year\n",
    "\n",
    "Using 2014 and 2016 as the training data, and 2018 as the test data\n",
    "\n",
    "Filtering features using `features_model_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(870, 282)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = housevotes_df[housevotes_df.year_x.isin([2014, 2016])]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(435, 282)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = housevotes_df[housevotes_df.year_x.isin([2018])]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(870, 280)\n",
      "(870,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.drop(['target', 'idx'], axis=1)\n",
    "y_train = train['target']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(435, 280)\n",
      "(435,)\n"
     ]
    }
   ],
   "source": [
    "X_test = test.drop(['target', 'idx'], axis=1)\n",
    "y_test = test['target']\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yr_district_id',\n",
       " 'year_x',\n",
       " 'state',\n",
       " 'district_id_x',\n",
       " 'winner_voteshare',\n",
       " 'total_dem_vote_share',\n",
       " 'total_rep_vote_share',\n",
       " 'dL1_winner',\n",
       " 'dL2_winner',\n",
       " 'dL3_winner',\n",
       " 'dL4_winner',\n",
       " 'dL5_winner',\n",
       " 'incumbent_L5_races',\n",
       " 'incumbent_L4_races',\n",
       " 'incumbent_L3_races',\n",
       " 'incumbent_L2_races',\n",
       " 'rep_L1_wins',\n",
       " 'rep_L5_wins',\n",
       " 'rep_L4_wins',\n",
       " 'rep_L3_wins',\n",
       " 'rep_L2_wins',\n",
       " 'dem_L1_wins',\n",
       " 'dem_L5_wins',\n",
       " 'dem_L4_wins',\n",
       " 'dem_L3_wins',\n",
       " 'dem_L2_wins',\n",
       " 'rep_L1_voteshare',\n",
       " 'rep_L5_voteshare',\n",
       " 'rep_L4_voteshare',\n",
       " 'rep_L3_voteshare',\n",
       " 'rep_L2_voteshare',\n",
       " 'dem_L1_voteshare',\n",
       " 'dem_L5_voteshare',\n",
       " 'dem_L4_voteshare',\n",
       " 'dem_L3_voteshare',\n",
       " 'dem_L2_voteshare',\n",
       " 'target',\n",
       " 'dem_incumbent_in_race',\n",
       " 'rep_incumbent_in_race',\n",
       " 'flipped',\n",
       " 'dmargin_45_55',\n",
       " 'mpop_share',\n",
       " 'fpop_share',\n",
       " 'm18_below_share',\n",
       " 'f18_below_share',\n",
       " '18_below_share',\n",
       " 'm18_above_share',\n",
       " 'f18_above_share',\n",
       " '18_above_share',\n",
       " 'm18_29_share',\n",
       " 'f18_29_share',\n",
       " '18_29_share',\n",
       " 'm30_44_share',\n",
       " 'f30_44_share',\n",
       " '30_44_share',\n",
       " 'm45_59_share',\n",
       " 'f45_59_share',\n",
       " '45_59_share',\n",
       " 'm60_74_share',\n",
       " 'f60_74_share',\n",
       " '60_74_share',\n",
       " 'm75_above_share',\n",
       " 'f75_above_share',\n",
       " '75_above_share',\n",
       " 'white_share',\n",
       " 'black_share',\n",
       " 'asian_share',\n",
       " 'hispanic_share',\n",
       " 'otherrace_share',\n",
       " 'native_share',\n",
       " 'nativeinstate_share',\n",
       " 'nativeoutofstate_share',\n",
       " 'foreignborn_share',\n",
       " 'hs_below_share',\n",
       " 'hs_share',\n",
       " 'somecollege_share',\n",
       " 'college_share',\n",
       " 'graddeg_share',\n",
       " 'samehouse_share',\n",
       " 'samecounty_share',\n",
       " 'samestate_share',\n",
       " 'diffstate_share',\n",
       " 'liveabroad_share',\n",
       " 'ptransport_share',\n",
       " 'walktowork_share',\n",
       " 'workathome_share',\n",
       " 'inschool_share',\n",
       " 'incollege_share',\n",
       " 'ingradschool_share',\n",
       " 'm_college_share',\n",
       " 'm_graddeg_share',\n",
       " 'm_phd_share',\n",
       " 'f_college_share',\n",
       " 'f_graddeg_share',\n",
       " 'f_phd_share',\n",
       " 'poverty_share',\n",
       " 'hhinc_10k_less_share',\n",
       " 'hhinc_30k_less_share',\n",
       " 'hhinc_50k_less_share',\n",
       " 'hhinc_75k_more_share',\n",
       " 'hhinc_100k_more_share',\n",
       " 'hhinc_125k_more_share',\n",
       " 'hhinc_150k_more_share',\n",
       " 'hhinc_200k_more_share',\n",
       " 'veteran_share',\n",
       " 'lfp_share',\n",
       " 'unemp_rate',\n",
       " 'armedforce_share',\n",
       " 'vacanthousing_share',\n",
       " 'renter_share',\n",
       " 'mortgage_share',\n",
       " 'l1_mpop_share',\n",
       " 'diff1_mpop_share',\n",
       " 'l1_fpop_share',\n",
       " 'diff1_fpop_share',\n",
       " 'l1_m18_below_share',\n",
       " 'diff1_m18_below_share',\n",
       " 'l1_f18_below_share',\n",
       " 'diff1_f18_below_share',\n",
       " 'l1_18_below_share',\n",
       " 'diff1_18_below_share',\n",
       " 'l1_m18_above_share',\n",
       " 'diff1_m18_above_share',\n",
       " 'l1_f18_above_share',\n",
       " 'diff1_f18_above_share',\n",
       " 'l1_18_above_share',\n",
       " 'diff1_18_above_share',\n",
       " 'l1_m18_29_share',\n",
       " 'diff1_m18_29_share',\n",
       " 'l1_f18_29_share',\n",
       " 'diff1_f18_29_share',\n",
       " 'l1_18_29_share',\n",
       " 'diff1_18_29_share',\n",
       " 'l1_m30_44_share',\n",
       " 'diff1_m30_44_share',\n",
       " 'l1_f30_44_share',\n",
       " 'diff1_f30_44_share',\n",
       " 'l1_30_44_share',\n",
       " 'diff1_30_44_share',\n",
       " 'l1_m45_59_share',\n",
       " 'diff1_m45_59_share',\n",
       " 'l1_f45_59_share',\n",
       " 'diff1_f45_59_share',\n",
       " 'l1_45_59_share',\n",
       " 'diff1_45_59_share',\n",
       " 'l1_m60_74_share',\n",
       " 'diff1_m60_74_share',\n",
       " 'l1_f60_74_share',\n",
       " 'diff1_f60_74_share',\n",
       " 'l1_60_74_share',\n",
       " 'diff1_60_74_share',\n",
       " 'l1_m75_above_share',\n",
       " 'diff1_m75_above_share',\n",
       " 'l1_f75_above_share',\n",
       " 'diff1_f75_above_share',\n",
       " 'l1_75_above_share',\n",
       " 'diff1_75_above_share',\n",
       " 'l1_white_share',\n",
       " 'diff1_white_share',\n",
       " 'l1_black_share',\n",
       " 'diff1_black_share',\n",
       " 'l1_asian_share',\n",
       " 'diff1_asian_share',\n",
       " 'l1_hispanic_share',\n",
       " 'diff1_hispanic_share',\n",
       " 'l1_otherrace_share',\n",
       " 'diff1_otherrace_share',\n",
       " 'l1_native_share',\n",
       " 'diff1_native_share',\n",
       " 'l1_nativeinstate_share',\n",
       " 'diff1_nativeinstate_share',\n",
       " 'l1_nativeoutofstate_share',\n",
       " 'diff1_nativeoutofstate_share',\n",
       " 'l1_foreignborn_share',\n",
       " 'diff1_foreignborn_share',\n",
       " 'l1_hs_below_share',\n",
       " 'diff1_hs_below_share',\n",
       " 'l1_hs_share',\n",
       " 'diff1_hs_share',\n",
       " 'l1_somecollege_share',\n",
       " 'diff1_somecollege_share',\n",
       " 'l1_college_share',\n",
       " 'diff1_college_share',\n",
       " 'l1_graddeg_share',\n",
       " 'diff1_graddeg_share',\n",
       " 'l1_samehouse_share',\n",
       " 'diff1_samehouse_share',\n",
       " 'l1_samecounty_share',\n",
       " 'diff1_samecounty_share',\n",
       " 'l1_samestate_share',\n",
       " 'diff1_samestate_share',\n",
       " 'l1_diffstate_share',\n",
       " 'diff1_diffstate_share',\n",
       " 'l1_liveabroad_share',\n",
       " 'diff1_liveabroad_share',\n",
       " 'l1_ptransport_share',\n",
       " 'diff1_ptransport_share',\n",
       " 'l1_walktowork_share',\n",
       " 'diff1_walktowork_share',\n",
       " 'l1_workathome_share',\n",
       " 'diff1_workathome_share',\n",
       " 'l1_inschool_share',\n",
       " 'diff1_inschool_share',\n",
       " 'l1_incollege_share',\n",
       " 'diff1_incollege_share',\n",
       " 'l1_ingradschool_share',\n",
       " 'diff1_ingradschool_share',\n",
       " 'l1_m_college_share',\n",
       " 'diff1_m_college_share',\n",
       " 'l1_m_graddeg_share',\n",
       " 'diff1_m_graddeg_share',\n",
       " 'l1_m_phd_share',\n",
       " 'diff1_m_phd_share',\n",
       " 'l1_f_college_share',\n",
       " 'diff1_f_college_share',\n",
       " 'l1_f_graddeg_share',\n",
       " 'diff1_f_graddeg_share',\n",
       " 'l1_f_phd_share',\n",
       " 'diff1_f_phd_share',\n",
       " 'l1_poverty_share',\n",
       " 'diff1_poverty_share',\n",
       " 'l1_hhinc_10k_less_share',\n",
       " 'diff1_hhinc_10k_less_share',\n",
       " 'l1_hhinc_30k_less_share',\n",
       " 'diff1_hhinc_30k_less_share',\n",
       " 'l1_hhinc_50k_less_share',\n",
       " 'diff1_hhinc_50k_less_share',\n",
       " 'l1_hhinc_75k_more_share',\n",
       " 'diff1_hhinc_75k_more_share',\n",
       " 'l1_hhinc_100k_more_share',\n",
       " 'diff1_hhinc_100k_more_share',\n",
       " 'l1_hhinc_125k_more_share',\n",
       " 'diff1_hhinc_125k_more_share',\n",
       " 'l1_hhinc_150k_more_share',\n",
       " 'diff1_hhinc_150k_more_share',\n",
       " 'l1_hhinc_200k_more_share',\n",
       " 'diff1_hhinc_200k_more_share',\n",
       " 'l1_veteran_share',\n",
       " 'diff1_veteran_share',\n",
       " 'l1_lfp_share',\n",
       " 'diff1_lfp_share',\n",
       " 'l1_unemp_rate',\n",
       " 'diff1_unemp_rate',\n",
       " 'l1_armedforce_share',\n",
       " 'diff1_armedforce_share',\n",
       " 'l1_vacanthousing_share',\n",
       " 'diff1_vacanthousing_share',\n",
       " 'l1_renter_share',\n",
       " 'diff1_renter_share',\n",
       " 'l1_mortgage_share',\n",
       " 'diff1_mortgage_share',\n",
       " 'median_household_income_scaled',\n",
       " 'income_lowest_quintile_scaled',\n",
       " 'income_second_quintile_scaled',\n",
       " 'income_third_quintile_scaled',\n",
       " 'income_fourth_quintile_scaled',\n",
       " 'income_highest_quintile_scaled',\n",
       " 'income_top_5_percent_scaled',\n",
       " 'median_gross_rent_scaled',\n",
       " 'median_monthly_owner_costs_scaled',\n",
       " 'L1_median_household_income_scaled',\n",
       " 'diff1_median_household_income_scaled',\n",
       " 'L1_income_lowest_quintile_scaled',\n",
       " 'diff1_income_lowest_quintile_scaled',\n",
       " 'L1_income_second_quintile_scaled',\n",
       " 'diff1_income_second_quintile_scaled',\n",
       " 'L1_income_third_quintile_scaled',\n",
       " 'diff1_income_third_quintile_scaled',\n",
       " 'L1_income_fourth_quintile_scaled',\n",
       " 'diff1_income_fourth_quintile_scaled',\n",
       " 'L1_income_highest_quintile_scaled',\n",
       " 'diff1_income_highest_quintile_scaled',\n",
       " 'L1_income_top_5_percent_scaled',\n",
       " 'diff1_income_top_5_percent_scaled',\n",
       " 'L1_median_gross_rent_scaled',\n",
       " 'diff1_median_gross_rent_scaled',\n",
       " 'L1_median_monthly_owner_costs_scaled',\n",
       " 'diff1_median_monthly_owner_costs_scaled',\n",
       " 'idx',\n",
       " '2014',\n",
       " '2016',\n",
       " '2018']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(housevotes_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy B: Train test split by district\n",
    "\n",
    "Filtering features using `features_model_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape for X_train: (1044, 281)\n",
      "Shape for y_train: (1044,)\n",
      "Shape for X_test: (261, 281)\n",
      "Shape for y_test: (261,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = district_train_test_split(dataframe=housevotes_df, \n",
    "                                                             idx_colname='idx',\n",
    "                                                             np_seed=1, \n",
    "                                                             tts_seed=1, \n",
    "                                                             test_size=0.2,\n",
    "                                                             cols_for_stratify=['target', 'flipped']\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.district_id_x.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null accuracy**: \"accuracy that could be achieved by always predicting the most frequent class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5210727969348659"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y_test.mean(), 1 - y_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Baseline model - Just vote history\n",
    "\n",
    "Use `dem_L1_wins` as the sole feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_baseline_model = ['dem_L1_wins']\n",
    "features_baseline_model = ['dem_L1_wins']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest, for baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = district_train_test_split(dataframe=housevotes_df, \n",
    "                                                             idx_colname='idx',\n",
    "                                                             np_seed=12345, \n",
    "                                                             tts_seed=12345, \n",
    "                                                             test_size=0.2,\n",
    "                                                             cols_for_stratify=['target', 'dmargin_45_55']\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044, 1)\n",
      "(261, 1)\n",
      "Test Accuracy score:  0.9578544061302682\n",
      "Test F1 score:  0.9551020408163265\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[features_baseline_model]\n",
    "X_test = X_test[features_baseline_model]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=23, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_class = rf.predict(X_test)\n",
    "y_pred_prob = rf.predict_proba(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133,   4],\n",
       "       [  7, 117]])"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted R wins</th>\n",
       "      <th>Predicted D wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual R wins</th>\n",
       "      <td>133</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual D wins</th>\n",
       "      <td>7</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predicted R wins  Predicted D wins\n",
       "Actual R wins               133                 4\n",
       "Actual D wins                 7               117"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(y_test, y_pred_class), columns = ['Predicted R wins', 'Predicted D wins'], \n",
    "             index = ['Actual R wins', 'Actual D wins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dem_L1_wins</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_name importance\n",
       "0  dem_L1_wins      1.000"
      ]
     },
     "execution_count": 686,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance = pd.DataFrame((zip(X_train.columns, rf.feature_importances_)))\n",
    "feat_importance.columns = ['feature_name', 'importance']\n",
    "feat_importance.importance = feat_importance.importance.apply(lambda x: '%.3f' % x) \n",
    "feat_importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.9578544061302682\n",
      "Test F1 score:  0.9551020408163265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ptw/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[133,   4],\n",
       "       [  7, 117]])"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "metrics.confusion_matrix(y_test, y_pred_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1, 36):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_class = knn.predict(X_test)\n",
    "#     print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "#     print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffcd8749240>]"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 36), scores)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.9578544061302682\n",
      "Test F1 score:  0.9551020408163265\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[133,   4],\n",
       "       [  7, 117]])"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9846743295019157\n",
      "0.946360153256705\n"
     ]
    }
   ],
   "source": [
    "ada_class = AdaBoostClassifier(random_state = 12345)\n",
    "ada_class.fit(X_train, y_train)\n",
    "print(ada_class.score(X_train, y_train))\n",
    "print(ada_class.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9281609195402298\n",
      "0.9578544061302682\n",
      "0.9281609195402298\n",
      "0.9578544061302682\n"
     ]
    }
   ],
   "source": [
    "xgb_class = XGBClassifier(random_state = 12345)\n",
    "xgb_rf_class = XGBRFClassifier(random_state = 12345)\n",
    "xgb_class.fit(X_train, y_train)\n",
    "print(xgb_class.score(X_train, y_train))\n",
    "print(xgb_class.score(X_test, y_test))\n",
    "\n",
    "xgb_rf_class.fit(X_train, y_train)\n",
    "print(xgb_rf_class.score(X_train, y_train))\n",
    "print(xgb_rf_class.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgFeatImp(imp_arr, feat_arr):\n",
    "    arrLen = imp_arr.shape[1]\n",
    "    avg_list = []\n",
    "    for i in range(arrLen):\n",
    "        avg_list.append(np.mean(imp_arr[:, i]))\n",
    "    avg_feat_importance = pd.DataFrame((zip(feat_arr, avg_list)))\n",
    "    avg_feat_importance.columns = ['feat', \"avg_imp\"]\n",
    "    return avg_feat_importance\n",
    "\n",
    "\n",
    "def plotFeature_i(i, importance_Arr, features_Arr):\n",
    "    feat = features_Arr[i]\n",
    "    fig = plt.figure()\n",
    "    plt.hist(importance_Arr[:, i], label=feat)\n",
    "    plt.legend\n",
    "\n",
    "\n",
    "def results(model,nloop):\n",
    "    model_list = []\n",
    "    acc_list = []\n",
    "    f1_list = []\n",
    "    y_pred_list = []\n",
    "    y_prob_list = []\n",
    "    importanceDF_list = []\n",
    "    importance_list = []\n",
    "    for loop_id in range(nloop):\n",
    "        X_train, X_test, y_train, y_test = district_train_test_split(dataframe=housevotes_df,\n",
    "                                                                 idx_colname='idx',\n",
    "                                                                 np_seed=loop_id,\n",
    "                                                                 tts_seed=loop_id+1,\n",
    "                                                                 test_size=0.2,\n",
    "                                                                 cols_for_stratify=[\n",
    "                                                                     'target', 'flipped']\n",
    "                                                                 )\n",
    "        X_train = X_train[model]\n",
    "        X_test = X_test[model]\n",
    "        rf = RandomForestClassifier(random_state=loop_id*2, n_estimators=100)\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "        feat_importance = pd.DataFrame(\n",
    "            (zip(X_train.columns, rf.feature_importances_)))\n",
    "        feat_importance.columns = ['feat', \"imp\"]\n",
    "\n",
    "        y_pred_class = rf.predict(X_test)\n",
    "        y_pred_prob = rf.predict_proba(X_test)\n",
    "\n",
    "#         print('Test Accuracy score: ',\n",
    "#               metrics.accuracy_score(y_test, y_pred_class))\n",
    "#         print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "        model_list.append(rf)\n",
    "        acc_list.append(metrics.accuracy_score(y_test, y_pred_class))\n",
    "        f1_list.append(metrics.f1_score(y_test, y_pred_class))\n",
    "        importanceDF_list.append(feat_importance)\n",
    "        importance_list.append(feat_importance.sort_values(by='feat').imp.values)\n",
    "\n",
    "    features_Arr = feat_importance.sort_values(by='feat').feat.values\n",
    "    importance_Arr = np.array(importance_list)\n",
    "    accscore = sum(acc_list) / len(acc_list)\n",
    "    print(f'Avg Accuracy score: {accscore}')\n",
    "    f1score = sum(f1_list) / len(f1_list)\n",
    "    print(f'Avg F1 score: {f1score}')\n",
    "    avg_feat_imp = avgFeatImp(importance_Arr, features_Arr)\n",
    "    feat_imp_table = avg_feat_imp.sort_values(by='avg_imp', ascending=False)\n",
    "    print(feat_imp_table)\n",
    "    for i in range(len(features_Arr)):\n",
    "        plotFeature_i(i, importance_Arr, features_Arr)\n",
    "    return accscore,f1score,feat_imp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Accuracy score: 0.9325670498084293\n",
      "Avg F1 score: 0.926908199307294\n",
      "          feat   avg_imp\n",
      "0  dem_L1_wins  0.515968\n",
      "1  dem_L2_wins  0.484032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9325670498084293, 0.926908199307294,           feat   avg_imp\n",
       " 0  dem_L1_wins  0.515968\n",
       " 1  dem_L2_wins  0.484032)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results(features_baseline_model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Accuracy score: 0.9337931034482767\n",
      "Avg F1 score: 0.9282199094676451\n"
     ]
    }
   ],
   "source": [
    "print(f'Avg Accuracy score: {sum(acc_list) / len(acc_list)}')\n",
    "print(f'Avg F1 score: {sum(f1_list) / len(f1_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          feat   avg_imp\n",
      "0  dem_L1_wins  0.531087\n",
      "1  dem_L2_wins  0.468913\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def avgFeatImp(imp_arr, feat_arr):\n",
    "    arrLen = imp_arr.shape[1]\n",
    "    avg_list = []\n",
    "    for i in range(arrLen):\n",
    "        avg_list.append(np.mean(imp_arr[:, i]))\n",
    "    avg_feat_importance = pd.DataFrame((zip(feat_arr, avg_list)))\n",
    "    avg_feat_importance.columns = ['feat', \"avg_imp\"]\n",
    "    return avg_feat_importance\n",
    "\n",
    "avg_feat_imp = avgFeatImp(importance_Arr, features_Arr)\n",
    "print(avg_feat_imp.sort_values(by='avg_imp', ascending=False))\n",
    "\n",
    "def plotFeature_i(i, importance_Arr, features_Arr):\n",
    "    feat = features_Arr[i]\n",
    "    fig = plt.figure()\n",
    "    plt.hist(importance_Arr[:,i], label=feat)\n",
    "    plt.legend\n",
    "\n",
    "for i in range(len(features_Arr)):\n",
    "    plotFeature_i(i, importance_Arr, features_Arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest, for baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_baseline_model = ['dem_L1_wins']\n",
    "features_baseline_model = ['dem_L1_wins','dem_L2_wins','2014','2016','2018']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = district_train_test_split(dataframe=housevotes_df, \n",
    "                                                             idx_colname='idx',\n",
    "                                                             np_seed=12345, \n",
    "                                                             tts_seed=12345, \n",
    "                                                             test_size=0.2,\n",
    "                                                             cols_for_stratify=['target', 'dmargin_45_55']\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044, 5)\n",
      "(261, 5)\n",
      "Test Accuracy score:  0.9540229885057471\n",
      "Test F1 score:  0.9508196721311476\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[features_baseline_model]\n",
    "X_test = X_test[features_baseline_model]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=23, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_class = rf.predict(X_test)\n",
    "y_pred_prob = rf.predict_proba(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133,   4],\n",
       "       [ 12, 112]])"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dem_L1_wins</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dem_L2_wins</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_name importance\n",
       "0  dem_L1_wins      0.625\n",
       "1  dem_L2_wins      0.348\n",
       "4         2018      0.015\n",
       "2         2014      0.006\n",
       "3         2016      0.006"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance = pd.DataFrame((zip(X_train.columns, rf.feature_importances_)))\n",
    "feat_importance.columns = ['feature_name', 'importance']\n",
    "feat_importance.importance = feat_importance.importance.apply(lambda x: '%.3f' % x) \n",
    "feat_importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044, 5)\n",
      "(261, 5)\n",
      "Test Accuracy score:  0.9386973180076629\n",
      "Test F1 score:  0.9338842975206612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ptw/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[132,   5],\n",
       "       [ 11, 113]])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[features_baseline_model]\n",
    "X_test = X_test[features_baseline_model]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "metrics.confusion_matrix(y_test, y_pred_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Baseline model - Just demographic data\n",
    "\n",
    "Use just ACS variables as features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_acs_only = [\n",
    " 'mpop_share',\n",
    " 'fpop_share',\n",
    " 'm18_below_share',\n",
    " 'f18_below_share',\n",
    " '18_below_share',\n",
    " 'm18_above_share',\n",
    " 'f18_above_share',\n",
    " '18_above_share',\n",
    " 'm18_29_share',\n",
    " 'f18_29_share',\n",
    " '18_29_share',\n",
    " 'm30_44_share',\n",
    " 'f30_44_share',\n",
    " '30_44_share',\n",
    " 'm45_59_share',\n",
    " 'f45_59_share',\n",
    " '45_59_share',\n",
    " 'm60_74_share',\n",
    " 'f60_74_share',\n",
    " '60_74_share',\n",
    " 'm75_above_share',\n",
    " 'f75_above_share',\n",
    " '75_above_share',\n",
    " 'white_share',\n",
    " 'black_share',\n",
    " 'asian_share',\n",
    " 'hispanic_share',\n",
    " 'otherrace_share',\n",
    " 'native_share',\n",
    " 'nativeinstate_share',\n",
    " 'nativeoutofstate_share',\n",
    " 'foreignborn_share',\n",
    " 'hs_below_share',\n",
    " 'hs_share',\n",
    " 'somecollege_share',\n",
    " 'college_share',\n",
    " 'graddeg_share',\n",
    " 'samehouse_share',\n",
    " 'samecounty_share',\n",
    " 'samestate_share',\n",
    " 'diffstate_share',\n",
    " 'liveabroad_share',\n",
    " 'ptransport_share',\n",
    " 'walktowork_share',\n",
    " 'workathome_share',\n",
    " 'inschool_share',\n",
    " 'incollege_share',\n",
    " 'ingradschool_share',\n",
    " 'm_college_share',\n",
    " 'm_graddeg_share',\n",
    " 'm_phd_share',\n",
    " 'f_college_share',\n",
    " 'f_graddeg_share',\n",
    " 'f_phd_share',\n",
    " 'poverty_share',\n",
    " 'hhinc_10k_less_share',\n",
    " 'hhinc_30k_less_share',\n",
    " 'hhinc_50k_less_share',\n",
    " 'hhinc_75k_more_share',\n",
    " 'hhinc_100k_more_share',\n",
    " 'hhinc_125k_more_share',\n",
    " 'hhinc_150k_more_share',\n",
    " 'hhinc_200k_more_share',\n",
    " 'veteran_share',\n",
    " 'lfp_share',\n",
    " 'unemp_rate',\n",
    " 'armedforce_share',\n",
    " 'vacanthousing_share',\n",
    " 'renter_share',\n",
    " 'mortgage_share',\n",
    " 'diff1_mpop_share',\n",
    " 'diff1_fpop_share',\n",
    " 'diff1_m18_below_share',\n",
    " 'diff1_f18_below_share',\n",
    " 'diff1_18_below_share',\n",
    " 'diff1_m18_above_share',\n",
    " 'diff1_f18_above_share',\n",
    " 'diff1_18_above_share',\n",
    " 'diff1_m18_29_share',\n",
    " 'diff1_f18_29_share',\n",
    " 'diff1_18_29_share',\n",
    " 'diff1_m30_44_share',\n",
    " 'diff1_f30_44_share',\n",
    " 'diff1_30_44_share',\n",
    " 'diff1_m45_59_share',\n",
    " 'diff1_f45_59_share',\n",
    " 'diff1_45_59_share',\n",
    " 'diff1_m60_74_share',\n",
    " 'diff1_f60_74_share',\n",
    " 'diff1_60_74_share',\n",
    " 'diff1_m75_above_share',\n",
    " 'diff1_f75_above_share',\n",
    " 'diff1_75_above_share',\n",
    " 'diff1_white_share',\n",
    " 'diff1_black_share',\n",
    " 'diff1_asian_share',\n",
    " 'diff1_hispanic_share',\n",
    " 'diff1_otherrace_share',\n",
    " 'diff1_native_share',\n",
    " 'diff1_nativeinstate_share',\n",
    " 'diff1_nativeoutofstate_share',\n",
    " 'diff1_foreignborn_share',\n",
    " 'diff1_hs_below_share',\n",
    " 'diff1_hs_share',\n",
    " 'diff1_somecollege_share',\n",
    " 'diff1_college_share',\n",
    " 'diff1_graddeg_share',\n",
    " 'diff1_samehouse_share',\n",
    " 'diff1_samecounty_share',\n",
    " 'diff1_samestate_share',\n",
    " 'diff1_diffstate_share',\n",
    " 'diff1_liveabroad_share',\n",
    " 'diff1_ptransport_share',\n",
    " 'diff1_walktowork_share',\n",
    " 'diff1_workathome_share',\n",
    " 'diff1_inschool_share',\n",
    " 'diff1_incollege_share',\n",
    " 'diff1_ingradschool_share',\n",
    " 'diff1_m_college_share',\n",
    " 'diff1_m_graddeg_share',\n",
    " 'diff1_m_phd_share',\n",
    " 'diff1_f_college_share',\n",
    " 'diff1_f_graddeg_share',\n",
    " 'diff1_f_phd_share',\n",
    " 'diff1_poverty_share',\n",
    " 'diff1_hhinc_10k_less_share',\n",
    " 'diff1_hhinc_30k_less_share',\n",
    " 'diff1_hhinc_50k_less_share',\n",
    " 'diff1_hhinc_75k_more_share',\n",
    " 'diff1_hhinc_100k_more_share',\n",
    " 'diff1_hhinc_125k_more_share',\n",
    " 'diff1_hhinc_150k_more_share',\n",
    " 'diff1_hhinc_200k_more_share',\n",
    " 'diff1_veteran_share',\n",
    " 'diff1_lfp_share',\n",
    " 'diff1_unemp_rate',\n",
    " 'diff1_armedforce_share',\n",
    " 'diff1_vacanthousing_share',\n",
    " 'diff1_renter_share',\n",
    " 'diff1_mortgage_share',\n",
    " 'median_household_income_scaled',\n",
    " 'income_lowest_quintile_scaled',\n",
    " 'income_second_quintile_scaled',\n",
    " 'income_third_quintile_scaled',\n",
    " 'income_fourth_quintile_scaled',\n",
    " 'income_highest_quintile_scaled',\n",
    " 'income_top_5_percent_scaled',\n",
    " 'median_gross_rent_scaled',\n",
    " 'median_monthly_owner_costs_scaled',\n",
    " 'diff1_median_household_income_scaled',\n",
    " 'diff1_income_lowest_quintile_scaled',\n",
    " 'diff1_income_second_quintile_scaled',\n",
    " 'diff1_income_third_quintile_scaled',\n",
    " 'diff1_income_fourth_quintile_scaled',\n",
    " 'diff1_income_highest_quintile_scaled',\n",
    " 'diff1_income_top_5_percent_scaled',\n",
    " 'diff1_median_gross_rent_scaled',\n",
    " 'diff1_median_monthly_owner_costs_scaled'\n",
    "] #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_acs_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = district_train_test_split(dataframe=housevotes_df, \n",
    "                                                             idx_colname='idx',\n",
    "                                                             np_seed=12345, \n",
    "                                                             tts_seed=12345, \n",
    "                                                             test_size=0.2,\n",
    "                                                             cols_for_stratify=['target', 'dmargin_45_55']\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044, 158)\n",
      "(261, 158)\n",
      "Test Accuracy score:  0.8659003831417624\n",
      "Test F1 score:  0.8571428571428572\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[features_acs_only].copy()\n",
    "X_test = X_test[features_acs_only].copy()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=23, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_class = rf.predict(X_test)\n",
    "y_pred_prob = rf.predict_proba(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[121,  16],\n",
       "       [ 19, 105]])"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted R wins</th>\n",
       "      <th>Predicted D wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual R wins</th>\n",
       "      <td>121</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual D wins</th>\n",
       "      <td>19</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predicted R wins  Predicted D wins\n",
       "Actual R wins               121                16\n",
       "Actual D wins                19               105"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(y_test, y_pred_class), columns = ['Predicted R wins', 'Predicted D wins'], \n",
    "             index = ['Actual R wins', 'Actual D wins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ptransport_share</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>white_share</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>renter_share</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>foreignborn_share</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>veteran_share</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>asian_share</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>native_share</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>median_monthly_owner_costs_scaled</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>median_gross_rent_scaled</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>samestate_share</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>walktowork_share</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f18_29_share</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>liveabroad_share</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>otherrace_share</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>black_share</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mpop_share</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>hispanic_share</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>f_graddeg_share</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fpop_share</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>poverty_share</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ingradschool_share</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18_29_share</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f18_above_share</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>somecollege_share</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>f_phd_share</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18_above_share</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>income_lowest_quintile_scaled</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>m_phd_share</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>hhinc_10k_less_share</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>m30_44_share</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>diff1_hhinc_125k_more_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>diff1_f18_29_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>diff1_hhinc_75k_more_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>diff1_hhinc_50k_less_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>hhinc_30k_less_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>diff1_mpop_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>diff1_fpop_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>diff1_f18_below_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>diff1_18_below_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>diff1_18_above_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>diff1_m18_29_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>diff1_18_29_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>diff1_m45_59_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>diff1_m60_74_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>diff1_75_above_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>diff1_asian_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>diff1_native_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>diff1_hs_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>diff1_college_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>diff1_graddeg_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>diff1_samehouse_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>diff1_samecounty_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>diff1_ingradschool_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>diff1_m_college_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>diff1_m_graddeg_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>diff1_m_phd_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>diff1_f_graddeg_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>diff1_poverty_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>diff1_hhinc_30k_less_share</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>diff1_median_monthly_owner_costs_scaled</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature_name importance\n",
       "42                          ptransport_share      0.114\n",
       "23                               white_share      0.054\n",
       "68                              renter_share      0.037\n",
       "31                         foreignborn_share      0.029\n",
       "63                             veteran_share      0.028\n",
       "25                               asian_share      0.026\n",
       "28                              native_share      0.024\n",
       "148        median_monthly_owner_costs_scaled      0.019\n",
       "147                 median_gross_rent_scaled      0.017\n",
       "39                           samestate_share      0.014\n",
       "43                          walktowork_share      0.014\n",
       "9                               f18_29_share      0.014\n",
       "41                          liveabroad_share      0.013\n",
       "27                           otherrace_share      0.013\n",
       "24                               black_share      0.013\n",
       "0                                 mpop_share      0.012\n",
       "26                            hispanic_share      0.012\n",
       "52                           f_graddeg_share      0.012\n",
       "1                                 fpop_share      0.012\n",
       "54                             poverty_share      0.010\n",
       "47                        ingradschool_share      0.009\n",
       "10                               18_29_share      0.009\n",
       "6                            f18_above_share      0.009\n",
       "34                         somecollege_share      0.008\n",
       "53                               f_phd_share      0.008\n",
       "7                             18_above_share      0.008\n",
       "141            income_lowest_quintile_scaled      0.008\n",
       "50                               m_phd_share      0.007\n",
       "55                      hhinc_10k_less_share      0.007\n",
       "11                              m30_44_share      0.007\n",
       "..                                       ...        ...\n",
       "130              diff1_hhinc_125k_more_share      0.002\n",
       "79                        diff1_f18_29_share      0.002\n",
       "128               diff1_hhinc_75k_more_share      0.002\n",
       "127               diff1_hhinc_50k_less_share      0.002\n",
       "56                      hhinc_30k_less_share      0.002\n",
       "70                          diff1_mpop_share      0.002\n",
       "71                          diff1_fpop_share      0.002\n",
       "73                     diff1_f18_below_share      0.002\n",
       "74                      diff1_18_below_share      0.002\n",
       "77                      diff1_18_above_share      0.002\n",
       "78                        diff1_m18_29_share      0.002\n",
       "80                         diff1_18_29_share      0.002\n",
       "84                        diff1_m45_59_share      0.002\n",
       "87                        diff1_m60_74_share      0.002\n",
       "92                      diff1_75_above_share      0.002\n",
       "95                         diff1_asian_share      0.002\n",
       "98                        diff1_native_share      0.002\n",
       "103                           diff1_hs_share      0.002\n",
       "105                      diff1_college_share      0.002\n",
       "106                      diff1_graddeg_share      0.002\n",
       "107                    diff1_samehouse_share      0.002\n",
       "108                   diff1_samecounty_share      0.002\n",
       "117                 diff1_ingradschool_share      0.002\n",
       "118                    diff1_m_college_share      0.002\n",
       "119                    diff1_m_graddeg_share      0.002\n",
       "120                        diff1_m_phd_share      0.002\n",
       "122                    diff1_f_graddeg_share      0.002\n",
       "124                      diff1_poverty_share      0.002\n",
       "126               diff1_hhinc_30k_less_share      0.002\n",
       "157  diff1_median_monthly_owner_costs_scaled      0.002\n",
       "\n",
       "[158 rows x 2 columns]"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance = pd.DataFrame((zip(X_train.columns, rf.feature_importances_)))\n",
    "feat_importance.columns = ['feature_name', 'importance']\n",
    "feat_importance.importance = feat_importance.importance.apply(lambda x: '%.3f' % x) \n",
    "feat_importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1, 36):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_class = knn.predict(X_test)\n",
    "#     print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "#     print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffc99509518>]"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl42+d16PnvAUAQJMFFBEmJmywSkm1JlqyFkkU5i2Mnqa3E8U5ZjTvNfXLjpKnT29t0GqeTyXUzzXTaTtLetI6b9N5edxzXFm3HqRMrdRIv2UTbonbJsiyRkgWKFBdw3xe88wcACqJAAiSxEOT5PI8eUz/8ALyE7cOX5z3vecUYg1JKqaXBkuwBKKWUShwN+koptYRo0FdKqSVEg75SSi0hGvSVUmoJ0aCvlFJLiAZ9pZRaQjToK6XUEqJBXymllhBbsgcwVUFBgVm1alWyh6GUUinl4MGDHcaYwkj3Lbigv2rVKurr65M9DKWUSiki8n4092l6RymllhAN+koptYRo0FdKqSVEg75SSi0hGvSVUmoJ0aCvlFJLiAZ9pZRaQhZN0G/qGuRv/uNdmruHkj2UmLrUM8xPj7ckexhKqUUiqqAvIreLyGkROSsij4Z5fKWIvC4ih0XkmIjsClxPE5F/FZHjInJKRL4a628gaHB0gu++0cBvznbE6y2S4h9fP8MX/+0QI+MTyR6KUmoRiBj0RcQKPA7cAawD9ojIuim3fQ2oNcZsBh4Evhu4/gCQbozZAGwFPi8iq2Iz9CutKXJS4LRT1+CNx8snzf4GL8ZA58BosoeilFoEopnpbwfOGmMajTGjwLPAXVPuMUBO4OtcoDnkepaI2IAMYBTonfeowxARdlS62N/QgTEmHm+RcJd6hmlsHwDA269BXyk1f9EE/VLAE/L3psC1UI8BD4lIE7AP+FLg+vPAANACXAD+X2NM53wGPJOd7gJae0do7BiI11skVF3j5VRVR/9IEkeilFosogn6Euba1Kn0HuBJY0wZsAt4SkQs+H9LmABKgArgyyJSedUbiDwsIvUiUt/e3j6rbyDUTrcLYNGkeOoavFgCn77O9JVSsRBN0G8CykP+Xsbl9E3QZ4FaAGNMHeAACoDfBf7DGDNmjGkDfgtUTX0DY8z3jTFVxpiqwsKInUGndY0rk+Jcx6IJ+vsbvOx0FwDgHdCZvlJq/qIJ+geANSJSISJ2/Au1L0255wJwG4CIrMUf9NsD128VvyxgB/BurAY/lYhQ7XZR1+jF50vtvL6nc5CmriE+uraIdJtFZ/pKqZiIGPSNMePAI8ArwCn8VTonReQbIvKpwG1fBj4nIkeBZ4DPGP9q6uOAEziB/4fH/zLGHIvD9zFpp7uAzoFR3mvri+fbxF3wt5WbVxdQ4EynQ4O+UioGojpExRizD/8Cbei1r4d8/Q5wc5jn9eMv20yY6kBef/9ZL9evyIlw98K1v6GDAmc6q4ucuJx2Te8opWJi0ezIDSrNy+AaVyb7Uzivb4xhf4OXarcLESE/y67pHaVUTCy6oA/+Kp63znmZSNG8fmPHAG19I5PVSK6sdLxasqmUioFFGfSr3QX0DY9zsrkn2UOZk+BvKcGgX+C04x0YXTSbzpRSybMog/6OynyAlE3x1DV0UJLrYGV+JgAup52RcR8Do9p/Ryk1P4sy6BdlO1hT5EzJoO/zGd5s7KTaXYCIf2eWKysdQFM8Sql5W5RBH/ypkfrznYyO+5I9lFk53dpH58DoZGoH/DN9QMs2lVLztmiDfrXbxeDoBMeaupM9lFkJ/nZSHRL0C5w601dKxcaiDfo3VbgQSb28fl2Dl1WuTEryMiavBWf6Xm2vrJSap0Ub9Jdl2VlXnJNSfXjGJ3y81eilOtBvJyg/KxD0daavlJqnRRv0wZ/XP3ihi+Gx1Kh6OdncS9/I+BX5fIB0m5Vsh01z+kqpeVvUQb/a7WJ03Meh97uSPZSo1DX6fyvZUem66jFXll3TO0qpeVvUQX/bqnysFkmZvP7+Bi/XLndSmJ1+1WMup+7KVUrN36IO+tmONDaW5U7OoBey0XEfB851TvbPn8ql/XeUUjGwqIM+QHWli6OebvpHxpM9lBkdbepmaGwibGoHAjN9Te8opeZp0Qf9ne4Cxn2GA+fjdjRvTNQ1eBG53EJiqgKnnc6BkZQ/HEYplVyLPuhvvWYZdquFNxd4Xn9/QwfrS3LIy7SHfdyVZcdnoHtoLMEjU0otJos+6GfYrWxembegF3OHxyY49H73tPl88Kd3QGv1lVLzs+iDPvhLN08099AzuDBnyYfe72J0wkf1NPl80P47SqnYWBJBf6e7AGPgzXMLc7a/v8GL1SJsqwifz4eQ/jt6bKJSah6WRNDfVJ6HI82yYFsy7G/o4MayXJzp0x9Z7JpsxaAzfaXU3C2JoG+3Wdi2Kn9BBv3+kXGONfVc0VUznLxMOxbRnL5San6WRNAHf17/dGsfHQssaB4438m4z8y4iAtgtQjLMu10aK2+Umoeogr6InK7iJwWkbMi8miYx1eKyOsiclhEjonIrsD1T4vIkZA/PhHZFOtvIhrBoPrmAtudW9fgxW61sPWaZRHvdTntOtNXSs1LxKAvIlbgceAOYB2wR0TWTbnta0CtMWYz8CDwXQBjzNPGmE3GmE3A7wHnjTFHYvkNROuGkhyy020LrnSzrsHLlmvycKRZI97rykqnU2f6Sql5iGamvx04a4xpNMaMAs8Cd025xwA5ga9zgeYwr7MHeGauA50vm9XC9oqFldfvGRzjRHMP1ZUzp3aC/DN9DfpKqbmbvlzkslLAE/L3JuCmKfc8BvxMRL4EZAEfDfM6u7n6hwUAIvIw8DDAypUroxjS3FS7Xbz6bhstPUMU52ZEfsI8NHUN8vjrZxmbmL5tQkf/CMbAztUzL+IGFTjTk74msf9sB73DY9x+Q3FSx6GUmptogr6EuTY1ku0BnjTGfEtEqoGnROQGY4wPQERuAgaNMSfCvYEx5vvA9wGqqqri1lzmlusK+cuXT/HysRb+8wcr4/U2ALx0tJln3vZQmjfzD5dtq5ZxY1leVK/pyrLTOzzO6LgPuy05a/Dfee0MLT3DGvSVSlHRBP0moDzk72Vcnb75LHA7gDGmTkQcQAHQFnj8QZKY2glaXZTNpvI8aus9fPYDFYiE+3kWG43tAyzPSee3j94as9cMtmLoHBhlRa4jZq87G57OocBvKCaun59SKj6imS4eANaISIWI2PEH8Jem3HMBuA1ARNYCDqA98HcL8AD+tYCkq6kq573Wfo429cT1fRra+6kscMb0NS+3YkhOimdswkdLzxAj4z66FmhLC6XUzCIGfWPMOPAI8ApwCn+VzkkR+YaIfCpw25eBz4nIUfwz+s8YY4Jpmg8BTcaYxtgPf/buvLEYR5qFvQc8kW+eI2MMje0DVBZmxfR1CwJBP1l99Vu6hwl2dm7pGUrKGJRS8xNNegdjzD5g35RrXw/5+h3g5mme+wawY+5DjK1sRxq7NhTz46PNfP2T68iwRy6VnC3vwCg9Q2O4C2M8089KbqdNT9fg5NeXeoZZX5KblHEopeZuyezIDbW7qpz+kXH2HW+Jy+s3tg8AxHymH0zvJKts09N5Oei39AwnZQxKqflZkkF/e0U+q1yZ1NbHJ8XT0N4PEPOZvjPdht1qoSNJnTabuoawWgSrRbikQV+plLQkg76I8EBVOW+d6+R8x0DMX7+xvZ90myViueZsiQgup53OZM30uwYpznWwPDtdZ/pKpaglGfQB7ttShkWIy2y/sX2AioIsLJbYlzS6nPakLeR6OgcpX5bJilyHLuQqlaKWbNBfkevgluuKeOFQE+MTvpi+dkN7f8xTO0GurPQkLuQOUZ6fQXFuhqZ3lEpRSzboA9RUldHaO8KvzrTH7DVHxifwdA3FfBE3yOW0J+XIxOGxCdr7RkJm+sNcrspVSqWKJR30b71+Oa4sO7UHmmL2mhe8g0z4TNxm+gXOdLwDIwkPuE2Bcs2y/AyKcx0MjU3QOzSe0DEopeZvSQd9u83CPZtL+cWp1pjtcm2IU7lmkCvLzvCYj8HRibi8/nQ8Xf4cfnCmD9DSq3l9pVLNkg76ADXbyhn3GX50+GJMXq+xw1+uWRmvnH7wgPQEp3iaAjX65fmZkx1KtYJHqdSz5IP+tcv9Tdj2HvDEJGXS0OZvtDbTIefzMdl/J8G1+p6uIew2C4XOdIoDM31dzFUq9Sz5oA+we1s5Z9r6OeLpnvdrNXbEvtFaqIKs5Mz0PZ2DlC3LwGIRCrPTsQi0dGt6R6lUo0Ef+OTGYjLSrPOu2TfG0NDWj7soPvl8gPzJVgyJnun7a/QB0qwWCnWDllIpSYM+oU3YWhgcnXtFindglN7h8bjO9F1Zyem06ekcomzZ5R3GK3IzuNSrQV+pVKNBP2D3tmATtktzfo2GtkDPnaL4BX1HmhVnui2h6Z3e4TF6hsYoz8+cvFac49CZvlIpSIN+wLZVy6goyKJ2Hn32GwN9fCoL4pfegWArhsSld5o6L5drBq3IdehCrlIpSIN+gL8JWxlvn++kMdAlc7bi1WhtKleWPaEz/WAf/fL8y99XSZ6D/pFx+ob1BC2lUokG/RDBJmzPHZzbDt2GODZaC+Vypif0yMRgH/0rZ/r+HwA621cqtWjQD7E8x8FHrivihYNza8LWGMdGa6EKEtxps6lrCGe6jbzMtMlrwVr9Zg36SqUUDfpT3L+1jLa+EQ6c75rV80bGJ7jQOYg7Tu0XQrmy0ukcGMXnS0z/nWCNvsjl32BW5AQ3aGmtvlKpRIP+FDevKcAiUNfondXzLngH8Zn4tV8I5XLamfAZeoYSk0/3dA1SFpLaAf9vRaCtGJRKNRr0p8hxpLGhNJe6ho5ZPS/ejdZCTfbfSUAFjzEGT+fQFYu44G9WV+BM15y+UikmqqAvIreLyGkROSsij4Z5fKWIvC4ih0XkmIjsCnlso4jUichJETkuIo5YfgPxUO0u4Iine1YbtYLn4iZipl8Q2KCViL76nQOjDI1NXLGIG1SSp7X6SqWaiEFfRKzA48AdwDpgj4ism3Lb14BaY8xm4EHgu4Hn2oAfAF8wxqwHbgEWfI3fTreLsQlD/Szy+o3t8W20FirYiqEzAYu5ky2V868O+itytFZfqVQTzUx/O3DWGNNojBkFngXumnKPAXICX+cCzYGvPw4cM8YcBTDGeI0xiW0EPwdVq5aRZhX2N0Sf14/nEYlTuSabrsU/vTNZrpl/9d6D4lwHzbqQq1RKiSbolwKh21SbAtdCPQY8JCJNwD7gS4Hr1wJGRF4RkUMi8mfzHG9CZNptbCrPizqvb4yhsb0/Ifl8gGWZaYgkJr0T3Jg1dSEX/LX6fcPj9I/oCVpKpYpogn64nUZTawX3AE8aY8qAXcBTImIBbMAHgE8H/nmPiNx21RuIPCwi9SJS394eu/Nq56PaXcDxiz30RrHjtKPf32gtUTN9m9XCsszEtGLwdA6xLDMtbNpK++orlXqiCfpNQHnI38u4nL4J+ixQC2CMqQMcQEHgub80xnQYYwbx/xawZeobGGO+b4ypMsZUFRYWzv67iIOdbhc+A283dka8tzGBi7hBiWrF0NQ1GDafD0wem6hBX6nUEU3QPwCsEZEKEbHjX6h9aco9F4DbAERkLf6g3w68AmwUkczAou6HgXdiNfh42rwyj3SbJaq8fqIarYVyORMV9IfCVu4AlEwem6h5faVSRcSgb4wZBx7BH8BP4a/SOSki3xCRTwVu+zLwORE5CjwDfMb4dQHfxv+D4whwyBjzcjy+kVhLt1mpWrWM/VHk9RvaEtNoLZTLmR73IxN9PsPFriHKwiziAhTl+BeUdaavVOqIqr7QGLMPf2om9NrXQ75+B7h5muf+AH/ZZsrZ6S7gb185TefAKPmB2vhwGjsS02gtVEEC0jutfcOMTvimnek70qy4suy06GEqSqUM3ZE7gx2VLgDejNCSoaG9P64Hp4TjcqbTMzTG6PjsG8NFy9M5fY1+0Ipch56Vq1QK0aA/g41luWTZrTOmeEbGJ/B0DuJOYD4f/Dl9gK7B+M32gzX6occkTlWcq7tylUolGvRnkGa1sL0if8bF3EQ2WgvlmmzFEL+8frBGf6a1ihW5Dj0rV6kUokE/gmq3i8b2AVqnCWzBnjuJqtEPCjZdi2crBk/nEMtz0nGkWae9pzg3g+7BMYZGF/xGa6UUGvQj2ukuAKBumtl+sLtmRYJ24wYFZ/rxXMxt6hqcdhE3aHKDls72lUoJGvQjWFucQ25G2rR5/Yb2flbkOBLSaC1UcKYfz/ROU9fQjIu4cHmDltbqK5UaNOhHYLUIOyrzpz1UpbF9IGE9d0LlOGykWSVuxyaOTfho6RmifIZFXPCndwBaunWmr1Qq0KAfhepKF57OoclqliBjDA0JbLQWSkRwZaXHrdNmc/cQPhO+0VqoyWMTNb2jVErQoB+FnavD5/U7+kfpS2Cjtani2YohWKM/3W7coAy7lbzMNE3vKJUiNOhHYU2RkwKn/aq8fjIarYXyt2KIU9APlGtGWsgFf4pHWzEolRo06EdBRNhR6aKu0Ysxl7tKByt33ElI70CwFUN06Z0Jn2FkPPqyyqauQawWmazOmYlu0FIqdWjQj9JOdwGtvSOTHTXBP9N3pFkmu00m2mzSO998+RQf/7tfMT4RXdsGT+cQJXkObNbI/4msyNVjE5VKFRr0o7TT7e/DE7o7t6G9n1WuxDZaC+VypjM0NhHxAPeh0Qlq6z287x3kV2eiO6TGE0WNflBxjgPvwCjDY7pBS6mFToN+lK5xZVKc6+DNkKDf2DGQ8EZrofKj3KC173gL/SPj2K0W9h7wzHhvkKdzaMaeO6GCtfrT7VpWSi0cGvSjJCJUu/15fV8gP56MRmuhCgJN1yLV6tfWe1jlyuT3qq/h1VNtETd0DY1O0NE/Ev1Mf/IwFQ36Si10GvRnYae7gM6BUU639vF+oNFaMmf6riz/rtyZFnPPdwzw1rlOHqgq58Ft5Yz7DC8eujjj6zYFK3ci7MYN0mMTlUodGvRnoTqQ169r8F4u1yxIYtB3Rk7vPHfQg0Xgvi1lrFmezeaVedTWe66oQppqslwzQo1+UPFkKwYN+kotdBr0Z6E0L4NrXJnsb/BOlmsmYzduUHCmP92xieMTPp4/2MQt1xVNzsZrqso509bPYU/3tK/b1BU4PCXK9E5Wuo0ch41LukFLqQVPg/4s7XS7eKvRy3utfazIcZCV4EZroTLsVrLs1mln+r86005r7wg1VeWT1z65sZiMNCvP1U+/oOvpHCTdZqEwOz3qsRTnZuhMX6kUoEF/lqrdBfSNjPPqqbakzvKDXM7p++/UHmjClWXn1uuLJq9lO9LYtaGYHx9tmbbU09M5ROmyDESiL0XVw1SUSg0a9GdpR2U+AP0jyeu5E8rltIet3unoH+EXp1q5d0spdtuV/5p3byunf2ScfccvhX3N2dToBxXnOmjWTptKLXhRBX0RuV1ETovIWRF5NMzjK0XkdRE5LCLHRGRX4PoqERkSkSOBP/8U628g0YqyHawJVOwsiJl+VjodYdI7Pzp8kXGfuSK1E7Rt1TIqCrKonaZm39M5GPUibtCKXAcd/SNxPahdKTV/EYO+iFiBx4E7gHXAHhFZN+W2rwG1xpjNwIPAd0MeazDGbAr8+UKMxp1Uwd25C2GmX+C8uv+OMYa9BzxsXpnHmuXZVz1HRHigqoy3z3dOViEF9QyN0Ts8PuuZfrAVRbQbtA6+38mJiz2zeg+l1PxFM9PfDpw1xjQaY0aBZ4G7ptxjgJzA17lAc+yGuPB8YmMJK3Ic3FCam+yhkJ9lp3Ng9IoSzCOebs609Yed5Qfdv6UMq0V47mDTFddnW6MftGIWxyaOTfh4+P87yKM/PDar91BKzV80Qb8UCM0DNAWuhXoMeEhEmoB9wJdCHqsIpH1+KSIfnM9gF4rtFfm8+ee3TbZBSCaXM51xn6F36PKibG29h4w0K5/cWDzt84pyHNxybSEvHGy6oglbsI/+XHL6EF2t/qun2vAOjHKyuZeewbFZvY9San6iCfrhSjim7uzZAzxpjCkDdgFPiYgFaAFWBtI+fwL8m4jkTHkuIvKwiNSLSH17e3QNwZRfsBVDsFZ/cHScHx9tYdeGYrIdaTM+t2ZbOW19I/zyvcufedMsN2YFXd6VG7lW/7l6D2lWwRh481z4YyiVUvERTdBvAkLzBGVcnb75LFALYIypAxxAgTFmxBjjDVw/CDQA1059A2PM940xVcaYqsLCwtl/F0vY5VYM/sXcfccv0T8yzu5t06d2gm69vogCp53akJp9T+cgznQbuRkz/8CYKtuRhjPdFrGCp7V3mNdPt/H71atwpFmuOo1MKRVf0QT9A8AaEakQETv+hdqXptxzAbgNQETW4g/67SJSGFgIRkQqgTVAY6wGr0JbMfhn+rX1HioKsti2alnE56ZZLdy7pYxXT7XR3ud/vqfL311zNjX6QdH01X/+YBM+A5/ecQ3bVuVr0FcqwSIGfWPMOPAI8ApwCn+VzkkR+YaIfCpw25eBz4nIUeAZ4DPGv7L4IeBY4PrzwBeMMZ3x+EaWKtdkemeUcx0DvH2ukweqyqIO2jVVZYz7DD867G/C5i/XnF0+P6g410HLDAu5xhieq/ewvSKfioIsdroLON3aN/kDRykVf1H1EDDG7MO/QBt67eshX78D3BzmeS8AL8xzjGoG+ZmXZ/rP1V9urhat1UXZbFmZx956D//5gxU0dQ3xwTVzS7EV5zp4r3X6NZm3z3Vy3jvII7euAS43sHuz0cudN5bM6T2VUrOjO3JTnM1qYVlmGq29Izx/sImPXFfE8pzI59qG2r2tnLNt/fziVBtDYxOzXsQNWpGbQVvfCGPTHMlYW9+EM93Grg0rALihJIfsdBt1jZriUSpRNOgvAi5nOv9xooW2vhEemKE2fzqf2FhCpt3Kt3/+HjD7cs2g4lwHxhA2XdM3PMa+4y3ceWMxmXb/L5g2q4WbKjWvr1QiadBfBFxZdroGxyhw2rltbVHkJ0zhTLfxiQ3FnGrpBaBszjP96Wv1f3KshaGxias2jO2odHGuY4AWbcusVEJo0F8ECpz+ss17NpeSZp3bv9KakBLP+cz0gbABfO8BD2uKnGwqz7vi+k53AYDO9pVKEA36i0CwgmemtguRVF2zjMqCLPKz7HM+IyB4Vu7Uss33Wvs44ulm97byq6qKrl+RzbLMNPZr0FcqIZJ3AoiKmZqqclbmZ4ZtrhYtEeH/uvsGmrvnnmbJcdjItFuvSu/UHvBgswh3b57avQMsFmFHpYu6Bi/GmDntD1BKRU+D/iJwQ2luTJq/3by6YF7PF5GrNmiNjvt48fBFPrp2+WQaaqqdbhc/PXEJT+cQK11zSy0ppaKj6R0VU8W5jity+q+924p3YJSabdPvHagO5PX3N3TEfXxKLXUa9FVMrcjJuGKmX1vfxPKcdD40w4Yvd2EWhdnpmtdXKgE06KuYKs510No3woTPcKlnmDdOt3H/1jJsM1QViQg73S72B/L6Sqn40aCvYmpFroMJn6G9b4QXDvmbqz2wNXJV0U63i47+ERqmnOSllIotDfoqpkry/LX6zT1DPFfv4aaKfFYVRD5LuLoymNfXFI9S8aRBX8XUihx/rf5LR5o57x2Meu9AeX4GpXkZ7D+rQV+peNKgr2IquCv3396+EGiuNv2RjaGCef03z3nx+TSvr1S8aNBXMZWXmUa6zcLouI87bywhw26N+rk7V7voHhzj1KXeOI5QqaVNg76KKRGZnO1Hc2RjqGBefzZ9eNr7RhgcHY98o1IK0KCv4qCiIIu1xTncWDa7XcIrch1UFmRFHfQveAe57Vtv8M2XT81lmEotSdqGQcXct2o24ZtjH51qt4t/P9LM+IRvxtr+4bEJ/uDpg/QOj/NOi6aDlIqWzvRVzOVn2aftsxNJtdtF/8g4xy/2zHjfYy+d5GRzL9ctz6axfUA3dSkVJQ36akHZUek/N3emev3n6j08e8DDF29xs3tbOT1DY3gHRhM1RKVSmgZ9taAUONO5fkU2b05zbu47zb187UcnqK508Scfu5bKQv/Gr8b2gUQOU6mUpUFfLTg7Kl0cON/JyPjEFdd7h8f44tMHyctM4zt7NmOzWnAXOgG0fYNSUYoq6IvI7SJyWkTOisijYR5fKSKvi8hhETkmIrvCPN4vIn8aq4GrxWun28XwmI8jF7onrxlj+NPaozR1DfH4726hMNu/ZlCal0G6zUKjBn2lohIx6IuIFXgcuANYB+wRkXVTbvsaUGuM2Qw8CHx3yuN/B/x0/sNVS8FNlS4sAnUhKZ5//nUjP3unlUfvuJ6qVfmT1y0WoaIgS9M7SkUpmpn+duCsMabRGDMKPAvcNeUeA+QEvs4FmoMPiMjdQCNwcv7DVUtBbkYa60tyJxdz32r08tf/cZpdG1bw2Q9UXHW/u9Cp6R2lohRN0C8FPCF/bwpcC/UY8JCINAH7gC8BiEgW8BXgL2Z6AxF5WETqRaS+vb09yqGrxWyn28XhC114Ogd55JnDXJOfyV/ftzFs7X9lYRaerqGr1gCUUleLJuiH22EztSh6D/CkMaYM2AU8JSIW/MH+74wxM07DjDHfN8ZUGWOqCgunP2FJLR3VbhdjE4aa79XRNzzGdx/aQrYjLey97kInEz7DBe9ggkepVOqJZkduExDaRKWMkPRNwGeB2wGMMXUi4gAKgJuA+0Xkb4A8wCciw8aYf5z3yNWitm1VPjaL0NIzzLdrbuT6FTnT3hss22xoH2DN8uxEDVGplBRN0D8ArBGRCuAi/oXa351yzwXgNuBJEVkLOIB2Y8wHgzeIyGNAvwZ8FY2sdBsPVJWRm2Hn3i3TH6oOUBko22zs0Ly+UpFEDPrGmHEReQR4BbAC/2KMOSki3wDqjTEvAV8G/llE/iv+1M9njO6LV/P0V/dujOo+Z7qN5TnpNLRpBY9SkUTVcM0Ysw//Am3ota+HfP0OcHOE13hsDuNTKiqVBU6d6SsVBd2RqxYFd1EWDW392nhNqQg06KtFobLASe/wuDZeUyrM1RBuAAAbzUlEQVQCDfpqUXAXBXrwtGmKR6mZaNBXi0JlQaDbZocu5io1Ew36alHQxmtKRUeDvloUgo3XGrTxmlIz0qCvFg13oVNn+kpFoEFfLRruwiwudA5q4zWlZqBBXy0alYVOfIZZN17z+Qx3P/5bnn37wrzev2dojI//3S95/XTbvF5HqXjSoK8WjdDGa7Nx6lIvRzzdfO9XjfPa3PXS0Wbea+3n9Xc16KuFS4O+WjQq53hebl3gsJZzHQMcON815/d/rt5/7MSJiz1zfg2l4k2Dvlo0go3XZnt04v4GL2XLMnCm29h7wBP5CWGcaunlWFMPeZlpnGrpY8Kn7SDUwqRBXy0qsz06cXzCx9vnOvnQtYXceWMJ+4630Dc8Nuv3ra33YLdaeOQjqxkam+CcbhJTC5QGfbWoVBZm0dgefeO14xd76B8ZZ6fbRU1VGUNjE/zkWMus3nNkfIIXD1/kY+uWc/PqAgBONmuKRy1MGvTVouIu9Dde6+iPrvFa8PD1HZUuNpXnce1yJ7X1s0vx/OKdNroHx6jZVs7qIid2m4WTzb2zHrtSiaBBXy0qk6doRZniqWvwct3ybAqc6YgINVXlHL7QzZnWvqjfc2+9h5JcBx9YXUCa1cL1K7J1pq8WLA36alGZTeO1kfEJ6t/vpNrtmrx2z+ZSbBaJekG3uXuIX59p5/6tZVgtAsD6khxONvdqb3+1IGnQV4tKsPFaNC2Wj1zoZnjMx86QoO9ypvPRtct58fBFRsd9EV/j+YNNGAP3by2fvLauJJfuwTEudg/N7ZtQKo406KtFJdh4LZqZ/v4GLxaBmypdV1zfva0c78Aor73bOuPzfT7Dcwc97HS7WOnKnLy+viQHQPP6akHSoK8WHXdRdGWbdQ1e1pfkkpuRdsX1D64pYHlOOrX1TTM+/81GL57OIXZvK7/i+toVOVhkfkG//nzngqn1Hx33xWTD2eDoOEc93TEYkZoPDfpq0XEXZOGJ0HhtaHSCw56uK1I7QTarhfu3lvHG6TYu9QxP+xq19R6yHTZ+Z/2KK65n2K24C528M8fF3KOebu7/pzp+dPjinJ4fS8YYvvLCMT75D7/h4Pud83qtv//FGe7+7m85r3sYkiqqoC8it4vIaRE5KyKPhnl8pYi8LiKHReSYiOwKXN8uIkcCf46KyD2x/gaUmirYeO39GRqv1b/fydiEuWIRN9QDW8vxGXjhUPjZfs/QGD89cYm7N5XiSLNe9fj6khxOXJzbTP83Zzuu+GcyPf3WBV4M/PCZ625l8P+28EJg/eP5gzP/BqXiK2LQFxEr8DhwB7AO2CMi66bc9jWg1hizGXgQ+G7g+gmgyhizCbgd+J6I2GI1eKXCcUdRtrm/wYvNImxblR/28VUFWdxUkc9z9Z6wVTgvHW1mZNxHTVV5mGfD+pJcLvUO4+0fmfX49zd0TP4zmRVAx5q6+caP3+HD1xZy/9YyfnKshf6R8Tm91mvvtuIdGKUwO53nDzYtmNTVUhTNTH87cNYY02iMGQWeBe6aco8BcgJf5wLNAMaYQWNM8L8SR+A+peKqIopum3UNXm4szyMrffo5SE1VOee9g7x97uq0Ru0BD2uLc7ihNCfMM2F96dwWc0fGJ6g/30V+lp3W3pGktXPoGhjlD35wiMLsdP5+9yb2bC9ncHSCfbPcrRxUW9/EihwHj925nku9w/zqTHuMR6yiFU3QLwVCf69rClwL9RjwkIg0AfuALwUfEJGbROQkcBz4QsgPAaXiwpluY0WOY9rF3N7hMY41dYfN54fataHY34Rtyg7dd5p7OX6xh5qqMkQk7HPXF+cCcGKWef3DF7oZGffxBx92A5d3DCeSz2f4r7VHaOsb5vFPb2FZlp0tK5dRWZh11WcRjUs9w7xxuo37tpbysXXLcWXZqZ1HqkjNTzRBP9x/1VNn7HuAJ40xZcAu4CkRsQAYY94yxqwHtgFfFRHHVW8g8rCI1ItIfXu7zgDU/Pl78ISfJR8414nPMG0+PyjDbp1swtYb0oQt2Fzt7k1T5z6X5WamUbYsY9Yz/WAZac22copzHZNtnxPp8dfP8sbpdr7+yXVsKs8DQETYXVXOwfe7OBvFHohQLxxqwmf86yR2m4V7Npfyi1Otc0p9qfmLJug3AaGJyzIC6ZsQnwVqAYwxdfhTOQWhNxhjTgEDwA1T38AY831jTJUxpqqwsDD60Ss1jcrCLBqmabxW1+DFbrOwZeWyiK+ze1s5w2M+fnLUn9YYGZ/gR0cu8rH1y1mWZZ/xuetLcnhnlkH/zQYvG0r9ZaTVlS7ebPTiS2D++zdnOvj2L97jrk0lPLTjmiseu2dLKVaLTJ4bEA1jDM/Ve7ipIp9Vgd3SNdvKGZswkwvEKrGiCfoHgDUiUiEidvwLtS9NuecCcBuAiKzFH/TbA8+xBa5fA1wHnI/R2JWalrvQSd80jdf2N3jZunJZ2KqbqW4sy+Xa5c7JtMbP32mle3CM3dMs4Ia6oSSXcx0DUbdqHhwd57Cnix2B30Cq3S68A6O81xZ9H6D5aOkZ4o+ePczqQid/de+Gq1JXRdkObr2+iBcOXWRsIvJuZYC3znVy3jt4xV6Ga5dns6k8j9ppFslVfEUM+oEc/CPAK8Ap/FU6J0XkGyLyqcBtXwY+JyJHgWeAzxj/v80PAEdF5AjwIvBFY0zy69DUojdd47WugVHeaemNmM8PCjZhO+rp5vSlPmrrmyjNy5hsoTyT4GLuqZbognb9+S7GJgw73f7XDqaf9p+Nf4pndNzHF58+xMjYBE88tJVMe/gF7t1V5XT0j0R9JGRtvYfsdBt33FB8xfWaqnLea+3naJM2pku0qOr0jTH7jDHXGmPcxphvBq593RjzUuDrd4wxNxtjbjTGbDLG/Cxw/SljzPrAtS3GmB/F71tR6jL3NBU8bzb6A2ikfH6oezaXkmYV/vur7/HrM+3cF9JcbSbrS/yLudF23KxrDJaR+tNOZcsyWZmfSV1j/IP+/73vFIcvdPPX929kdZFz2vtuua6QwuzIu5XBv2C+73gLd24qIcN+5W9Vd95YjCPNMq/afzU3uiNXLUoluRk40ixXzfTrGr1k2q1sLMuL+rWCTdj2Hb+EMfDA1rKonleUnU6B0x71Yu7+Bi+byvOumGXvdPvz+vGsa//x0Wae3H+ez+xcxSc3lsx4r81q4b4tZbx+uo223ul3KwP85GgLw2O+sKmwbEcauzYU8+OjzQyNTr9zWsWebpRSi5K/8drVPXj2N3jZtiofu212852aqnJ+euISN692UZ6fGfkJ+FND60tyowr6vcNjHG/q5pGPrL7ierXbxbMHPJxs7pnVDyqAtr5hvvbiCYYjdAutP9/JlpV5/PmutVG97gNVZfzTLxv44eGLfCFQWhrO3noP1y3PZmNZbtjHd1eV88NDF9l3vIX7ovxBCvDG6TbqGr382e9cH9VvXKniK88f45qCTL54y+rIN8+DzvTVolVZeGW3zbbeYc629Uedzw/1oWsLuXdLKX9065pZPW99SQ5nWvtm7AME8HZjsIz0yrWC6kAH0LmUbv7gzQv8/FQrvUNjM/65qSKfxz+9JeofhO5CJ9tWLaP2wPQLsacv9XHU003NtvJp9zJsr8hnlStzVieVnWnt44tPH+J7v2zkO6+eifp5C11b7zDPH2qibzj+25h0pq8WLXdBFj893sLI+ATpNutkbnw2+fwgq0X4ds2mWT9vfUku4z7De5f62TDNjBf8aSe7zcLmlVfO5otyHKwucrK/wcvnZ5hVTzXhMzxf7+EDqwt46rM3zXrckTxQVc6fPX+Mg+93URWmlUVtvYc0q3DP5un3MogID1SV87evnOZ8x8BkSed0+kfG+cIPDpJpt/Lhawv5zmtn2Lwyj1uuK5r395NsLxy6yITPRJ06nA+d6atFy110ZeO1ugYv2Q7b5AJrIlzurT/zYu7+Bi9V14QvI93pdnHgfGfUZZIAvz3bQXPP8FVtn2PlExuKybJbwy7Ejo77Jg+Kz4+wl+G+LWVYBJ47OPNs3xjDoy8c41zHAN/Zs5lv12ziuuXZ/PHeIzR1Td9YLxUE9zJsX5U/WXUWTxr01aJVWXBl2eb+Bi87Kl0JzQOvzM8kO902YzuGzoFRTs1QRlpd6WJwdIJjTdH3oq+t95CXmcbH1i2f9ZijkZVu45MbS3j5+NVN2F491UrnwCgPRLGXYUWug1uuK+L5g02Mz/BD7V/3n+cnx1r48sevY6e7gAy7lSce2srEhOEPnz4UMX22kNW/30VjxwAPVMV/lg8a9NUiVhlSttnUNciFzsHJHHmiWCzC2sCZudN5azLtFL72f0fl7Or1uwZG+dnJVu7eVEq6LfIGtLmq2eZvwvbysSs36O+t97Aix8GH1kS3u76mqozW3hF+fSb8Fp5DF7r45r5T3HZ90WRPIoCKgiz+9oGNHG3q4S9/cmru30iS1R7wkGW38omNxZFvjgEN+mrRygppvBZcCN25OrFBH/wpnndb+qYtu9zfECwjDZ92WpZlZ11xTtTN1/79yEVGJ6Zv+xwrW1bmsbrIeUXNfkvPEL9678qD4iO59Xp/E7ZwqSJv/wh/+PQhVuQ6+HbNJixTXvP2G4p5+EOVPPXm+/z7kdRr69A/Ms7Lx1u488aSaTfExZoGfbWo+XvwDFDX4MWVZefaouyEj2F9SS5DYxOc6wjfqGx/QwfbK/JJs07/v+NOt4uDF7oYHps5jWGMYW99ExtKc1lXEr7tc6z4dyuXBZqw+Xcdv3DQ31xtNj9wQpuwdYQ0YZvwGf547xG8A6M88emt5GamhX3+n/3OdWxflc+jLxznvdbEtKyIlZ8cbWZwdIKaOK29hKNBXy1q7kInje39/ny+23XVTDERgj33w52k1dY7TEP7QMQy0mq3i9FxH4cudM1438nmXk619FKToPzwPZvLsFmE5+qb8PkMtfVNVFdeeVB8NGq2lTPuM1ccEfnfXz3Dr8908BefWs8NpdMvvtusFv7xdzeTlW7jCz84OOeDXpKhtt7D6iInm8tntwdjPjToq0WtsjCLvuFxLvUOJzyfH+QudGK3WcJW8EyWkVbO3Mtne0U+VotErNffe8BDus3Cp2Zo+xxLhdnpgSZsTfy2oYMLnYPUbJv9D5xgE7a9gdr/N0638Q+vneG+LWU8GMUsuCjHwT/s2cz5jgG+8sKxlGjkdratj0MXutldNf1ehnjQoK8WNXdICdxcNmXFQprVwvUrssMu5u4/6yXHYYuYisl2pLGhNHfGvP7w2AT/fuQid9ywgtyM8KmQeNi9rZyO/lEefeE42Y6rm6vN5nXOtPXz8vEW/njvEa5bns1f3n1D1AGx2u3if/+d63n5WAtP7j8/pzEkUm19EzaLcM+WxPyADtKgrxa1YAXPihwHFRE2/8TT+kAFz9QZaF1j9GWk1W4XRz3dDEyTvnjl5CV6h8fjvoA71YevLaQoO52L3UN86saSqFpWh/PJjcVkpFn5o2cOMzFheOKhrVc1aovkCx+u5KNrl/PNl0/xmzMdtPeNzPhnNEKLingZm/Dxw0NN3La2iAJnekLfW3fkqkWtJDcDZ7qNnatdCf0Veqr1Jbk887aHpq6hyd49nk5/Gel/unlVVK+x0+3iiTcaOHC+M+wu1L0HPJTnZ0yWeCaKzWrhvq1lPPFGw7w2g2U70vjExmKeP9jE3z6wcU4/pEWEb9XcyJ3/8Bse+p9vRbx/XXEOL//RBxL+38Zr77bR0T+a8B/QoEFfLXIWi/DUZ7dTuiwjqeO4vDO3dzLoB/P5O6epz5+q6pp80qz+vP7UoO/pHGR/g5c/+di1SVmsfuQjq7mpIn/WTeGm+m93rqOmqpztFVe3dohWbkYaez+/g1dPtV11rmuod1t6efqtCxy60MXWa+b+fnNRe8BDUXY6H7428ScFatBXi97mKI5FjLfrV+RgEXinuYfbb1gBcLmMdHl0W+8z7FY2ly8L21//uXoPInB/Anq3hJOVbotJD5xsR9q8An5QcW7GVcc9TjUwMs6Lhy+y94AnoUG/tXeY10+38fkPu7HNUKYbL5rTVyoBMuxW3IVOTgQWc40x1DV4qXbPLu1U7XZx4mIPPYOXj2Cc8BmeP9jEB9cUUpKX3N9oUom/lUQxPznWMu06STwED4pPRmoHNOgrlTA3lOZOlm2e6xjwl5HOsqJop9uFz8Bb5y7P9n8TbK6WpCCSynYHW0kcb0nI+/mbqzWxfVV+0goLNOgrlSDrS3Jo7R2ho39ksvQy2nx+0KaVeaTbLFekeGrrPSzLTOOj61K/xXCibVm5jMrCLGoTdGzjgfNdnOsYSOgO3Kk06CuVIOtCFnPrGr0U5zpYNcudq+k2K9tW5U9u0uoaGOXnJ1u5e3N8m6stViLC7qpy6t/vuuqUtXiorffgTLexa8OKuL/XdDToK5Ug64v9rQROXOzhzQYv1ZVzKyOtdrt491If3v4RfhRorhavvvlLwT1bSrFaZFYneM1F3/AYLx9r4c4bixPWXC2cqIK+iNwuIqdF5KyIPBrm8ZUi8rqIHBaRYyKyK3D9YyJyUESOB/55a6y/AaVSRW5mGuX5Gbx4+CLegdE5neAFl0/+qmv0sveAh41luVy/Ir7N1RazomyHv5XEwYuzOqhmtl4+1sLQ2ERU5wzEU8SgLyJW4HHgDmAdsEdE1k257WtArTFmM/Ag8N3A9Q7gTmPMBuD3gadiNXClUtH64lzOtvnTCHMN+htLc3Gm2/gfvz7Hu5f6klYFspjUVJXT0T/CG6fb4/Yee+s9rElwc7VwopnpbwfOGmMajTGjwLPAXVPuMUBwqpELNAMYYw4bY4InLJwEHCKS2D3HSi0gwU1aK/MzKVs2u3x+kM1qYXtFPkc83aTbLNx5Y0ksh7gkfeS6Qgqz0+OW4jnT2sfhC93UJLi5WjjRJJZKgdBPogmYetLyY8DPRORLQBbw0TCvcx9w2BgzEuYxpZaE9YE2y/Nt/lZd6eK1d9vYtaE4oc3VFiub1cK9W0r5H78+R1vfMEXZjqife7yph982hD/1K+itRm9SmquFE03QD/djaeru5j3Ak8aYb4lINfCUiNxgjPEBiMh64K+Bj4d9A5GHgYcBVq5cGe3YlUo5m8uXUeBMZ9eG+R2Nd9vaIv7x9bP8XvXMu05V9GqqyvneLxt58dBFPh9yLONMzrb1sfv7dQyORj6j994tpQlvrhaOROo7HQjijxljfifw968CGGP+KuSek8DtxhhP4O+NwA5jTJuIlAGvAf/JGPPbSAOqqqoy9fX1c/1+lFJqzu5/Yj+dg6O8+icfjpiGGRgZ567Hf0vXwCg/+sObIwZ0R5olrqkdETlojKmKdF80Of0DwBoRqRARO/6F2pem3HMBuC3wxmsBB9AuInnAy8BXown4SimVTDXbymlsH4h4Qpkxhq/+8DiN7f38w57NlOdnkmG3zvgn2bn8oIhB3xgzDjwCvAKcwl+lc1JEviEinwrc9mXgcyJyFHgG+Izx/wrxCLAa+D9F5Ejgj24bVEotSJ/YUEyW3Rr2kPZQT735Pi8dbebLH7+Onatnt6s62SKmdxJN0ztKqWT6yvPH+PGxZg78Hx8lK/3qZc/DF7qo+V4dH1pTyD//b1VJaWUdTizTO0optWTUbCvzN2E7dnUTts6BUf7w6UMsz3Hw7ZpNCybgz4YGfaWUCrFl5TLchVlX1exP+Az/5dnDdPSP8sSnt5KbmZqlshr0lVIqhIhQE2jCFtw9DfCdV8/w6zMdPPap9Wwoy03iCOdHg75SSk1x75YyrBbhuYP+2f4bp9v4zmtnuHdLKXu2p3bbCw36Sik1RWF2+mQTtgveQf547xGuW57NN+/esGBKL+dKg75SSoWxO9CE7d4nfsvEhOGJh7aSYU/9Mws06CulVBi3BJqwdfSP8rcPbEza8YaxlrxO/koptYDZrBb+n3s34B0Y5fYb5tcraSHRoK+UUtO4be3yZA8h5jS9o5RSS4gGfaWUWkI06Cul1BKiQV8ppZYQDfpKKbWEaNBXSqklRIO+UkotIRr0lVJqCVlwJ2eJSDvw/jQPFwAdCRzOfKXaeEHHnCipNuZUGy8svTFfY4wpjHTTggv6MxGR+miOA1soUm28oGNOlFQbc6qNF3TM09H0jlJKLSEa9JVSaglJtaD//WQPYJZSbbygY06UVBtzqo0XdMxhpVROXyml1Pyk2kxfKaXUPKRE0BeR20XktIicFZFHkz2eaIjIeRE5LiJHRKQ+2eMJR0T+RUTaROREyLV8Efm5iJwJ/HNZMsc41TRjfkxELgY+6yMisiuZYwwlIuUi8rqInBKRkyLyXwLXF+znPMOYF/Ln7BCRt0XkaGDMfxG4XiEibwU+570iYk/2WGHG8T4pIudCPuNNMX9zY8yC/gNYgQagErADR4F1yR5XFOM+DxQkexwRxvghYAtwIuTa3wCPBr5+FPjrZI8zijE/Bvxpssc2zXiLgS2Br7OB94B1C/lznmHMC/lzFsAZ+DoNeAvYAdQCDwau/xPwB8kea4TxPgncH8/3ToWZ/nbgrDGm0RgzCjwL3JXkMS0KxphfAZ1TLt8F/Gvg638F7k7ooCKYZswLljGmxRhzKPB1H3AKKGUBf84zjHnBMn79gb+mBf4Y4Fbg+cD1BfM5zzDeuEuFoF8KeEL+3sQC/w8wwAA/E5GDIvJwsgczC8uNMS3g/58fKEryeKL1iIgcC6R/FkyqJJSIrAI245/VpcTnPGXMsIA/ZxGxisgRoA34Of4MQbcxZjxwy4KKHVPHa4wJfsbfDHzGfyci6bF+31QI+hLmWiqUHN1sjNkC3AH8oYh8KNkDWsSeANzAJqAF+FZyh3M1EXECLwB/bIzpTfZ4ohFmzAv6czbGTBhjNgFl+DMEa8PdlthRTW/qeEXkBuCrwPXANiAf+Eqs3zcVgn4TUB7y9zKgOUljiZoxpjnwzzbgRfz/EaaCVhEpBgj8sy3J44nIGNMa+B/IB/wzC+yzFpE0/MHzaWPMDwOXF/TnHG7MC/1zDjLGdANv4M+R54mILfDQgowdIeO9PZBaM8aYEeB/EYfPOBWC/gFgTWAV3g48CLyU5DHNSESyRCQ7+DXwceDEzM9aMF4Cfj/w9e8D/57EsUQlGDwD7mEBfdYiIsD/BE4ZY74d8tCC/ZynG/MC/5wLRSQv8HUG8FH8axGvA/cHblswn/M04303ZCIg+NcfYv4Zp8TmrEBp2N/jr+T5F2PMN5M8pBmJSCX+2T2ADfi3hThmEXkGuAV/Z79W4L8BP8Jf8bASuAA8YIxZMAun04z5FvwpB4O/aurzwXx5sonIB4BfA8cBX+Dyn+PPkS/Iz3mGMe9h4X7OG/Ev1FrxT2ZrjTHfCPy/+Cz+VMlh4KHALDqpZhjva0Ah/rT2EeALIQu+sXnvVAj6SimlYiMV0jtKKaViRIO+UkotIRr0lVJqCdGgr5RSS4gGfaWUWkI06Cul1BKiQV8ppZYQDfpKKbWE/P+lOUtPn+97TgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 36), scores)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.8812260536398467\n",
      "Test F1 score:  0.8764940239043826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[120,  17],\n",
       "       [ 14, 110]])"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9473180076628352\n",
      "0.8505747126436781\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86       137\n",
      "           1       0.87      0.81      0.84       124\n",
      "\n",
      "    accuracy                           0.85       261\n",
      "   macro avg       0.85      0.85      0.85       261\n",
      "weighted avg       0.85      0.85      0.85       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_class = AdaBoostClassifier(random_state = 12345)\n",
    "ada_class.fit(X_train, y_train)\n",
    "print(ada_class.score(X_train, y_train))\n",
    "print(ada_class.score(X_test, y_test))\n",
    "pred = ada_class.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9904214559386973\n",
      "0.8812260536398467\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.89       137\n",
      "           1       0.88      0.87      0.87       124\n",
      "\n",
      "    accuracy                           0.88       261\n",
      "   macro avg       0.88      0.88      0.88       261\n",
      "weighted avg       0.88      0.88      0.88       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_class = XGBClassifier(random_state = 12345)\n",
    "xgb_rf_class = XGBRFClassifier(random_state = 12345)\n",
    "xgb_class.fit(X_train, y_train)\n",
    "print(xgb_class.score(X_train, y_train))\n",
    "print(xgb_class.score(X_test, y_test))\n",
    "pred = xgb_class.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8726053639846744\n",
      "0.8390804597701149\n"
     ]
    }
   ],
   "source": [
    "xgb_rf_class.fit(X_train, y_train)\n",
    "print(xgb_rf_class.score(X_train, y_train))\n",
    "print(xgb_rf_class.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[122,  15],\n",
       "       [ 16, 108]])"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted R wins</th>\n",
       "      <th>Predicted D wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual R wins</th>\n",
       "      <td>122</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual D wins</th>\n",
       "      <td>16</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predicted R wins  Predicted D wins\n",
       "Actual R wins               122                15\n",
       "Actual D wins                16               108"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm, columns = ['Predicted R wins', 'Predicted D wins'], \n",
    "             index = ['Actual R wins', 'Actual D wins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044, 158)\n",
      "(261, 158)\n",
      "Test Accuracy score:  0.842911877394636\n",
      "Test F1 score:  0.831275720164609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ptw/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[119,  18],\n",
       "       [ 23, 101]])"
      ]
     },
     "execution_count": 587,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train[features_acs_only].copy()\n",
    "X_test = X_test[features_acs_only].copy()\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: All features from House votes and ACS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model_1 = [\n",
    " 'incumbent_L5_races',\n",
    " 'incumbent_L4_races',\n",
    " 'incumbent_L3_races',\n",
    " 'incumbent_L2_races',\n",
    " 'rep_L1_wins',\n",
    " 'rep_L5_wins',\n",
    " 'rep_L4_wins',\n",
    " 'rep_L3_wins',\n",
    " 'rep_L2_wins',\n",
    " 'dem_L1_wins',\n",
    " 'dem_L5_wins',\n",
    " 'dem_L4_wins',\n",
    " 'dem_L3_wins',\n",
    " 'dem_L2_wins',\n",
    " 'rep_L1_voteshare',\n",
    " 'rep_L5_voteshare',\n",
    " 'rep_L4_voteshare',\n",
    " 'rep_L3_voteshare',\n",
    " 'rep_L2_voteshare',\n",
    " 'dem_L1_voteshare',\n",
    " 'dem_L5_voteshare',\n",
    " 'dem_L4_voteshare',\n",
    " 'dem_L3_voteshare',\n",
    " 'dem_L2_voteshare',\n",
    " 'dem_incumbent_in_race',\n",
    " 'rep_incumbent_in_race',\n",
    " 'mpop_share',\n",
    " 'fpop_share',\n",
    " 'm18_below_share',\n",
    " 'f18_below_share',\n",
    " '18_below_share',\n",
    " 'm18_above_share',\n",
    " 'f18_above_share',\n",
    " '18_above_share',\n",
    " 'm18_29_share',\n",
    " 'f18_29_share',\n",
    " '18_29_share',\n",
    " 'm30_44_share',\n",
    " 'f30_44_share',\n",
    " '30_44_share',\n",
    " 'm45_59_share',\n",
    " 'f45_59_share',\n",
    " '45_59_share',\n",
    " 'm60_74_share',\n",
    " 'f60_74_share',\n",
    " '60_74_share',\n",
    " 'm75_above_share',\n",
    " 'f75_above_share',\n",
    " '75_above_share',\n",
    " 'white_share',\n",
    " 'black_share',\n",
    " 'asian_share',\n",
    " 'hispanic_share',\n",
    " 'otherrace_share',\n",
    " 'native_share',\n",
    " 'nativeinstate_share',\n",
    " 'nativeoutofstate_share',\n",
    " 'foreignborn_share',\n",
    " 'hs_below_share',\n",
    " 'hs_share',\n",
    " 'somecollege_share',\n",
    " 'college_share',\n",
    " 'graddeg_share',\n",
    " 'samehouse_share',\n",
    " 'samecounty_share',\n",
    " 'samestate_share',\n",
    " 'diffstate_share',\n",
    " 'liveabroad_share',\n",
    " 'ptransport_share',\n",
    " 'walktowork_share',\n",
    " 'workathome_share',\n",
    " 'inschool_share',\n",
    " 'incollege_share',\n",
    " 'ingradschool_share',\n",
    " 'm_college_share',\n",
    " 'm_graddeg_share',\n",
    " 'm_phd_share',\n",
    " 'f_college_share',\n",
    " 'f_graddeg_share',\n",
    " 'f_phd_share',\n",
    " 'poverty_share',\n",
    " 'hhinc_10k_less_share',\n",
    " 'hhinc_30k_less_share',\n",
    " 'hhinc_50k_less_share',\n",
    " 'hhinc_75k_more_share',\n",
    " 'hhinc_100k_more_share',\n",
    " 'hhinc_125k_more_share',\n",
    " 'hhinc_150k_more_share',\n",
    " 'hhinc_200k_more_share',\n",
    " 'veteran_share',\n",
    " 'lfp_share',\n",
    " 'unemp_rate',\n",
    " 'armedforce_share',\n",
    " 'vacanthousing_share',\n",
    " 'renter_share',\n",
    " 'mortgage_share',\n",
    " 'diff1_mpop_share',\n",
    " 'diff1_fpop_share',\n",
    " 'diff1_m18_below_share',\n",
    " 'diff1_f18_below_share',\n",
    " 'diff1_18_below_share',\n",
    " 'diff1_m18_above_share',\n",
    " 'diff1_f18_above_share',\n",
    " 'diff1_18_above_share',\n",
    " 'diff1_m18_29_share',\n",
    " 'diff1_f18_29_share',\n",
    " 'diff1_18_29_share',\n",
    " 'diff1_m30_44_share',\n",
    " 'diff1_f30_44_share',\n",
    " 'diff1_30_44_share',\n",
    " 'diff1_m45_59_share',\n",
    " 'diff1_f45_59_share',\n",
    " 'diff1_45_59_share',\n",
    " 'diff1_m60_74_share',\n",
    " 'diff1_f60_74_share',\n",
    " 'diff1_60_74_share',\n",
    " 'diff1_m75_above_share',\n",
    " 'diff1_f75_above_share',\n",
    " 'diff1_75_above_share',\n",
    " 'diff1_white_share',\n",
    " 'diff1_black_share',\n",
    " 'diff1_asian_share',\n",
    " 'diff1_hispanic_share',\n",
    " 'diff1_otherrace_share',\n",
    " 'diff1_native_share',\n",
    " 'diff1_nativeinstate_share',\n",
    " 'diff1_nativeoutofstate_share',\n",
    " 'diff1_foreignborn_share',\n",
    " 'diff1_hs_below_share',\n",
    " 'diff1_hs_share',\n",
    " 'diff1_somecollege_share',\n",
    " 'diff1_college_share',\n",
    " 'diff1_graddeg_share',\n",
    " 'diff1_samehouse_share',\n",
    " 'diff1_samecounty_share',\n",
    " 'diff1_samestate_share',\n",
    " 'diff1_diffstate_share',\n",
    " 'diff1_liveabroad_share',\n",
    " 'diff1_ptransport_share',\n",
    " 'diff1_walktowork_share',\n",
    " 'diff1_workathome_share',\n",
    " 'diff1_inschool_share',\n",
    " 'diff1_incollege_share',\n",
    " 'diff1_ingradschool_share',\n",
    " 'diff1_m_college_share',\n",
    " 'diff1_m_graddeg_share',\n",
    " 'diff1_m_phd_share',\n",
    " 'diff1_f_college_share',\n",
    " 'diff1_f_graddeg_share',\n",
    " 'diff1_f_phd_share',\n",
    " 'diff1_poverty_share',\n",
    " 'diff1_hhinc_10k_less_share',\n",
    " 'diff1_hhinc_30k_less_share',\n",
    " 'diff1_hhinc_50k_less_share',\n",
    " 'diff1_hhinc_75k_more_share',\n",
    " 'diff1_hhinc_100k_more_share',\n",
    " 'diff1_hhinc_125k_more_share',\n",
    " 'diff1_hhinc_150k_more_share',\n",
    " 'diff1_hhinc_200k_more_share',\n",
    " 'diff1_veteran_share',\n",
    " 'diff1_lfp_share',\n",
    " 'diff1_unemp_rate',\n",
    " 'diff1_armedforce_share',\n",
    " 'diff1_vacanthousing_share',\n",
    " 'diff1_renter_share',\n",
    " 'diff1_mortgage_share',\n",
    " 'median_household_income_scaled',\n",
    " 'income_lowest_quintile_scaled',\n",
    " 'income_second_quintile_scaled',\n",
    " 'income_third_quintile_scaled',\n",
    " 'income_fourth_quintile_scaled',\n",
    " 'income_highest_quintile_scaled',\n",
    " 'income_top_5_percent_scaled',\n",
    " 'median_gross_rent_scaled',\n",
    " 'median_monthly_owner_costs_scaled',\n",
    " 'diff1_median_household_income_scaled',\n",
    " 'diff1_income_lowest_quintile_scaled',\n",
    " 'diff1_income_second_quintile_scaled',\n",
    " 'diff1_income_third_quintile_scaled',\n",
    " 'diff1_income_fourth_quintile_scaled',\n",
    " 'diff1_income_highest_quintile_scaled',\n",
    " 'diff1_income_top_5_percent_scaled',\n",
    " 'diff1_median_gross_rent_scaled',\n",
    " 'diff1_median_monthly_owner_costs_scaled',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest, for Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = district_train_test_split(dataframe=housevotes_df, \n",
    "                                                             idx_colname='idx',\n",
    "                                                             np_seed=12345, \n",
    "                                                             tts_seed=12345, \n",
    "                                                             test_size=0.2,\n",
    "                                                             cols_for_stratify=['target', 'dmargin_45_55']\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044, 184)\n",
      "(261, 184)\n",
      "Test Accuracy score:  0.9693486590038314\n",
      "Test F1 score:  0.9674796747967479\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[features_model_1]\n",
    "X_test = X_test[features_model_1]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=23, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_class = rf.predict(X_test)\n",
    "y_pred_prob = rf.predict_proba(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[134,   3],\n",
       "       [  5, 119]])"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted R wins</th>\n",
       "      <th>Predicted D wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual R wins</th>\n",
       "      <td>134</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual D wins</th>\n",
       "      <td>5</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predicted R wins  Predicted D wins\n",
       "Actual R wins               134                 3\n",
       "Actual D wins                 5               119"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(y_test, y_pred_class), columns = ['Predicted R wins', 'Predicted D wins'], \n",
    "             index = ['Actual R wins', 'Actual D wins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dem_L1_voteshare</td>\n",
       "      <td>0.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rep_L1_voteshare</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dem_L2_wins</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dem_L2_voteshare</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dem_L1_wins</td>\n",
       "      <td>0.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rep_L1_wins</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rep_L2_voteshare</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rep_L2_wins</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dem_L3_voteshare</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dem_L3_wins</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>dem_incumbent_in_race</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>rep_incumbent_in_race</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rep_L5_wins</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rep_L3_voteshare</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dem_L4_wins</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ptransport_share</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rep_L3_wins</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incumbent_L3_races</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rep_L4_voteshare</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incumbent_L4_races</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>foreignborn_share</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>incumbent_L2_races</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dem_L5_voteshare</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>asian_share</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>incumbent_L5_races</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>median_monthly_owner_costs_scaled</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>renter_share</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>veteran_share</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rep_L4_wins</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dem_L5_wins</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>diff1_f75_above_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>diff1_m75_above_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>diff1_60_74_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>diff1_m60_74_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>diff1_45_59_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>diff1_f45_59_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>diff1_30_44_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>diff1_f30_44_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>diff1_m30_44_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>f_college_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>diff1_f18_29_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>diff1_18_29_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>diff1_fpop_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>diff1_f18_below_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>poverty_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>lfp_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>diff1_mpop_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>diff1_18_above_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>diff1_m18_below_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>diff1_median_monthly_owner_costs_scaled</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>diff1_18_below_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>diff1_m18_above_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>diff1_f18_above_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>income_fourth_quintile_scaled</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>diff1_f60_74_share</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>mortgage_share</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>income_third_quintile_scaled</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>diff1_white_share</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>diff1_median_gross_rent_scaled</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>median_household_income_scaled</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>184 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature_name importance\n",
       "19                          dem_L1_voteshare      0.083\n",
       "14                          rep_L1_voteshare      0.079\n",
       "13                               dem_L2_wins      0.078\n",
       "23                          dem_L2_voteshare      0.069\n",
       "9                                dem_L1_wins      0.062\n",
       "4                                rep_L1_wins      0.054\n",
       "18                          rep_L2_voteshare      0.045\n",
       "8                                rep_L2_wins      0.035\n",
       "22                          dem_L3_voteshare      0.029\n",
       "12                               dem_L3_wins      0.027\n",
       "24                     dem_incumbent_in_race      0.023\n",
       "25                     rep_incumbent_in_race      0.023\n",
       "5                                rep_L5_wins      0.017\n",
       "17                          rep_L3_voteshare      0.016\n",
       "11                               dem_L4_wins      0.014\n",
       "68                          ptransport_share      0.014\n",
       "7                                rep_L3_wins      0.014\n",
       "2                         incumbent_L3_races      0.012\n",
       "16                          rep_L4_voteshare      0.011\n",
       "1                         incumbent_L4_races      0.011\n",
       "57                         foreignborn_share      0.009\n",
       "3                         incumbent_L2_races      0.009\n",
       "20                          dem_L5_voteshare      0.008\n",
       "51                               asian_share      0.008\n",
       "0                         incumbent_L5_races      0.008\n",
       "174        median_monthly_owner_costs_scaled      0.007\n",
       "94                              renter_share      0.007\n",
       "89                             veteran_share      0.006\n",
       "6                                rep_L4_wins      0.006\n",
       "10                               dem_L5_wins      0.006\n",
       "..                                       ...        ...\n",
       "117                    diff1_f75_above_share      0.001\n",
       "116                    diff1_m75_above_share      0.001\n",
       "115                        diff1_60_74_share      0.001\n",
       "113                       diff1_m60_74_share      0.001\n",
       "112                        diff1_45_59_share      0.001\n",
       "111                       diff1_f45_59_share      0.001\n",
       "109                        diff1_30_44_share      0.001\n",
       "108                       diff1_f30_44_share      0.001\n",
       "107                       diff1_m30_44_share      0.001\n",
       "77                           f_college_share      0.001\n",
       "105                       diff1_f18_29_share      0.001\n",
       "106                        diff1_18_29_share      0.001\n",
       "97                          diff1_fpop_share      0.001\n",
       "99                     diff1_f18_below_share      0.001\n",
       "80                             poverty_share      0.001\n",
       "90                                 lfp_share      0.001\n",
       "96                          diff1_mpop_share      0.001\n",
       "103                     diff1_18_above_share      0.001\n",
       "98                     diff1_m18_below_share      0.001\n",
       "183  diff1_median_monthly_owner_costs_scaled      0.001\n",
       "100                     diff1_18_below_share      0.001\n",
       "101                    diff1_m18_above_share      0.001\n",
       "102                    diff1_f18_above_share      0.001\n",
       "170            income_fourth_quintile_scaled      0.000\n",
       "114                       diff1_f60_74_share      0.000\n",
       "95                            mortgage_share      0.000\n",
       "169             income_third_quintile_scaled      0.000\n",
       "119                        diff1_white_share      0.000\n",
       "182           diff1_median_gross_rent_scaled      0.000\n",
       "166           median_household_income_scaled      0.000\n",
       "\n",
       "[184 rows x 2 columns]"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance = pd.DataFrame((zip(X_train.columns, rf.feature_importances_)))\n",
    "feat_importance.columns = ['feature_name', 'importance']\n",
    "feat_importance.importance = feat_importance.importance.apply(lambda x: '%.3f' % x) \n",
    "feat_importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.9616858237547893\n",
      "Test F1 score:  0.9596774193548389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ptw/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[132,   5],\n",
       "       [  5, 119]])"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1, 36):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_class = knn.predict(X_test)\n",
    "#     print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "#     print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffc79968898>]"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 36), scores)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.9731800766283525\n",
      "Test F1 score:  0.97165991902834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[134,   3],\n",
       "       [  4, 120]])"
      ]
     },
     "execution_count": 660,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=8)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9923371647509579\n",
      "0.9386973180076629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       137\n",
      "           1       0.94      0.94      0.94       124\n",
      "\n",
      "    accuracy                           0.94       261\n",
      "   macro avg       0.94      0.94      0.94       261\n",
      "weighted avg       0.94      0.94      0.94       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_class = AdaBoostClassifier(random_state = 12345)\n",
    "ada_class.fit(X_train, y_train)\n",
    "print(ada_class.score(X_train, y_train))\n",
    "print(ada_class.score(X_test, y_test))\n",
    "pred = ada_class.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9770114942528736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       137\n",
      "           1       0.97      0.98      0.98       124\n",
      "\n",
      "    accuracy                           0.98       261\n",
      "   macro avg       0.98      0.98      0.98       261\n",
      "weighted avg       0.98      0.98      0.98       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_class = XGBClassifier(random_state = 12345)\n",
    "xgb_rf_class = XGBRFClassifier(random_state = 12345)\n",
    "xgb_class.fit(X_train, y_train)\n",
    "print(xgb_class.score(X_train, y_train))\n",
    "print(xgb_class.score(X_test, y_test))\n",
    "pred = xgb_class.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9626436781609196\n",
      "0.9770114942528736\n"
     ]
    }
   ],
   "source": [
    "xgb_rf_class.fit(X_train, y_train)\n",
    "print(xgb_rf_class.score(X_train, y_train))\n",
    "print(xgb_rf_class.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[133,   4],\n",
       "       [  2, 122]])"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted R wins</th>\n",
       "      <th>Predicted D wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual R wins</th>\n",
       "      <td>133</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual D wins</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predicted R wins  Predicted D wins\n",
       "Actual R wins               133                 4\n",
       "Actual D wins                 2               122"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm, columns = ['Predicted R wins', 'Predicted D wins'], \n",
    "             index = ['Actual R wins', 'Actual D wins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: All features minus collinear ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_model_2 = [\n",
    " 'incumbent_L5_races',\n",
    " 'incumbent_L4_races',\n",
    " 'incumbent_L3_races',\n",
    " 'incumbent_L2_races',\n",
    "#  'rep_L1_wins',\n",
    "#  'rep_L5_wins',\n",
    "#  'rep_L4_wins',\n",
    "#  'rep_L3_wins',\n",
    "#  'rep_L2_wins',\n",
    " 'dem_L1_wins',\n",
    " 'dem_L5_wins',\n",
    " 'dem_L4_wins',\n",
    " 'dem_L3_wins',\n",
    " 'dem_L2_wins',\n",
    "#  'rep_L1_voteshare',\n",
    "#  'rep_L5_voteshare',\n",
    "#  'rep_L4_voteshare',\n",
    "#  'rep_L3_voteshare',\n",
    "#  'rep_L2_voteshare',\n",
    " 'dem_L1_voteshare',\n",
    " 'dem_L5_voteshare',\n",
    " 'dem_L4_voteshare',\n",
    " 'dem_L3_voteshare',\n",
    " 'dem_L2_voteshare',\n",
    " 'dem_incumbent_in_race',\n",
    " 'rep_incumbent_in_race',\n",
    "#  'mpop_share',\n",
    " 'fpop_share',\n",
    "#  'm18_below_share',\n",
    "#  'f18_below_share',\n",
    " '18_below_share',\n",
    "#  'm18_above_share',\n",
    "#  'f18_above_share',\n",
    " '18_above_share',\n",
    "#  'm18_29_share',\n",
    "#  'f18_29_share',\n",
    " '18_29_share',\n",
    "#  'm30_44_share',\n",
    "#  'f30_44_share',\n",
    " '30_44_share',\n",
    "#  'm45_59_share',\n",
    "#  'f45_59_share',\n",
    " '45_59_share',\n",
    "#  'm60_74_share',\n",
    "#  'f60_74_share',\n",
    " '60_74_share',\n",
    "#  'm75_above_share',\n",
    "#  'f75_above_share',\n",
    " '75_above_share',\n",
    " 'white_share',\n",
    " 'black_share',\n",
    " 'asian_share',\n",
    " 'hispanic_share',\n",
    " 'otherrace_share',\n",
    " # 'native_share',\n",
    " # 'nativeinstate_share',\n",
    " 'nativeoutofstate_share',\n",
    " 'foreignborn_share',\n",
    " 'hs_below_share',\n",
    " 'hs_share',\n",
    " 'somecollege_share',\n",
    " 'college_share',\n",
    " 'graddeg_share',\n",
    " 'samehouse_share',\n",
    " 'samecounty_share',\n",
    " 'samestate_share',\n",
    " 'diffstate_share',\n",
    " 'liveabroad_share',\n",
    " 'ptransport_share',\n",
    " 'walktowork_share',\n",
    " 'workathome_share',\n",
    " 'inschool_share',\n",
    " 'incollege_share',\n",
    " 'ingradschool_share',\n",
    " 'm_college_share',\n",
    " 'm_graddeg_share',\n",
    " 'm_phd_share',\n",
    " # 'f_college_share',\n",
    " 'f_graddeg_share',\n",
    " 'f_phd_share',\n",
    " 'poverty_share',\n",
    " 'hhinc_10k_less_share',\n",
    " 'hhinc_30k_less_share',\n",
    " 'hhinc_50k_less_share',\n",
    " 'hhinc_75k_more_share',\n",
    " 'hhinc_100k_more_share',\n",
    " 'hhinc_125k_more_share',\n",
    " 'hhinc_150k_more_share',\n",
    " 'hhinc_200k_more_share',\n",
    " 'veteran_share',\n",
    " 'lfp_share',\n",
    " 'unemp_rate',\n",
    " 'armedforce_share',\n",
    " 'vacanthousing_share',\n",
    " 'renter_share',\n",
    " 'mortgage_share',\n",
    " # 'l1_mpop_share',\n",
    " # 'diff1_mpop_share',\n",
    "#  'l1_fpop_share',\n",
    " 'diff1_fpop_share',\n",
    " # 'l1_m18_below_share',\n",
    " # 'diff1_m18_below_share',\n",
    " # 'l1_f18_below_share',\n",
    " # 'diff1_f18_below_share',\n",
    "#  'l1_18_below_share',\n",
    " 'diff1_18_below_share',\n",
    " # 'l1_m18_above_share',\n",
    " # 'diff1_m18_above_share',\n",
    " # 'l1_f18_above_share',\n",
    " # 'diff1_f18_above_share',\n",
    "#  'l1_18_above_share',\n",
    " 'diff1_18_above_share',\n",
    " # 'l1_m18_29_share',\n",
    " # 'diff1_m18_29_share',\n",
    " # 'l1_f18_29_share',\n",
    " # 'diff1_f18_29_share',\n",
    "#  'l1_18_29_share',\n",
    " 'diff1_18_29_share',\n",
    " # 'l1_m30_44_share',\n",
    " # 'diff1_m30_44_share',\n",
    " # 'l1_f30_44_share',\n",
    " # 'diff1_f30_44_share',\n",
    "#  'l1_30_44_share',\n",
    " 'diff1_30_44_share',\n",
    " # 'l1_m45_59_share',\n",
    " # 'diff1_m45_59_share',\n",
    " # 'l1_f45_59_share',\n",
    " # 'diff1_f45_59_share',\n",
    "#  'l1_45_59_share',\n",
    " 'diff1_45_59_share',\n",
    " # 'l1_m60_74_share',\n",
    " # 'diff1_m60_74_share',\n",
    " # 'l1_f60_74_share',\n",
    " # 'diff1_f60_74_share',\n",
    "#  'l1_60_74_share',\n",
    " 'diff1_60_74_share',\n",
    " # 'l1_m75_above_share',\n",
    " # 'diff1_m75_above_share',\n",
    " # 'l1_f75_above_share',\n",
    " # 'diff1_f75_above_share',\n",
    "#  'l1_75_above_share',\n",
    " 'diff1_75_above_share',\n",
    "#  'l1_white_share',\n",
    " 'diff1_white_share',\n",
    "#  'l1_black_share',\n",
    " 'diff1_black_share',\n",
    "#  'l1_asian_share',\n",
    " 'diff1_asian_share',\n",
    "#  'l1_hispanic_share',\n",
    " 'diff1_hispanic_share',\n",
    "#  'l1_otherrace_share',\n",
    " 'diff1_otherrace_share',\n",
    " # 'l1_native_share',\n",
    " # 'diff1_native_share',\n",
    " # 'l1_nativeinstate_share',\n",
    " # 'diff1_nativeinstate_share',\n",
    "#  'l1_nativeoutofstate_share',\n",
    " 'diff1_nativeoutofstate_share',\n",
    "#  'l1_foreignborn_share',\n",
    " 'diff1_foreignborn_share',\n",
    "#  'l1_hs_below_share',\n",
    " 'diff1_hs_below_share',\n",
    "#  'l1_hs_share',\n",
    " 'diff1_hs_share',\n",
    "#  'l1_somecollege_share',\n",
    " 'diff1_somecollege_share',\n",
    "#  'l1_college_share',\n",
    " 'diff1_college_share',\n",
    "#  'l1_graddeg_share',\n",
    " 'diff1_graddeg_share',\n",
    "#  'l1_samehouse_share',\n",
    " 'diff1_samehouse_share',\n",
    "#  'l1_samecounty_share',\n",
    " 'diff1_samecounty_share',\n",
    "#  'l1_samestate_share',\n",
    " 'diff1_samestate_share',\n",
    "#  'l1_diffstate_share',\n",
    " 'diff1_diffstate_share',\n",
    "#  'l1_liveabroad_share',\n",
    " 'diff1_liveabroad_share',\n",
    "#  'l1_ptransport_share',\n",
    " 'diff1_ptransport_share',\n",
    "#  'l1_walktowork_share',\n",
    " 'diff1_walktowork_share',\n",
    "#  'l1_workathome_share',\n",
    " 'diff1_workathome_share',\n",
    "#  'l1_inschool_share',\n",
    " 'diff1_inschool_share',\n",
    "#  'l1_incollege_share',\n",
    " 'diff1_incollege_share',\n",
    "#  'l1_ingradschool_share',\n",
    " 'diff1_ingradschool_share',\n",
    "#  'l1_m_college_share',\n",
    " 'diff1_m_college_share',\n",
    "#  'l1_m_graddeg_share',\n",
    " 'diff1_m_graddeg_share',\n",
    "#  'l1_m_phd_share',\n",
    " 'diff1_m_phd_share',\n",
    " # 'l1_f_college_share',\n",
    " # 'diff1_f_college_share',\n",
    "#  'l1_f_graddeg_share',\n",
    " 'diff1_f_graddeg_share',\n",
    "#  'l1_f_phd_share',\n",
    " 'diff1_f_phd_share',\n",
    "#  'l1_poverty_share',\n",
    " 'diff1_poverty_share',\n",
    "#  'l1_hhinc_10k_less_share',\n",
    " 'diff1_hhinc_10k_less_share',\n",
    "#  'l1_hhinc_30k_less_share',\n",
    " 'diff1_hhinc_30k_less_share',\n",
    "#  'l1_hhinc_50k_less_share',\n",
    " 'diff1_hhinc_50k_less_share',\n",
    "#  'l1_hhinc_75k_more_share',\n",
    " 'diff1_hhinc_75k_more_share',\n",
    "#  'l1_hhinc_100k_more_share',\n",
    " 'diff1_hhinc_100k_more_share',\n",
    "#  'l1_hhinc_125k_more_share',\n",
    " 'diff1_hhinc_125k_more_share',\n",
    "#  'l1_hhinc_150k_more_share',\n",
    " 'diff1_hhinc_150k_more_share',\n",
    "#  'l1_hhinc_200k_more_share',\n",
    " 'diff1_hhinc_200k_more_share',\n",
    "#  'l1_veteran_share',\n",
    " 'diff1_veteran_share',\n",
    "#  'l1_lfp_share',\n",
    " 'diff1_lfp_share',\n",
    "#  'l1_unemp_rate',\n",
    " 'diff1_unemp_rate',\n",
    "#  'l1_armedforce_share',\n",
    " 'diff1_armedforce_share',\n",
    "#  'l1_vacanthousing_share',\n",
    " 'diff1_vacanthousing_share',\n",
    "#  'l1_renter_share',\n",
    " 'diff1_renter_share',\n",
    "#  'l1_mortgage_share',\n",
    " 'diff1_mortgage_share',\n",
    " 'median_household_income_scaled',\n",
    " 'income_lowest_quintile_scaled',\n",
    " 'income_second_quintile_scaled',\n",
    " 'income_third_quintile_scaled',\n",
    " 'income_fourth_quintile_scaled',\n",
    " 'income_highest_quintile_scaled',\n",
    " 'income_top_5_percent_scaled',\n",
    " 'median_gross_rent_scaled',\n",
    " 'median_monthly_owner_costs_scaled',\n",
    "#  'L1_median_household_income_scaled',\n",
    " 'diff1_median_household_income_scaled',\n",
    "#  'L1_income_lowest_quintile_scaled',\n",
    " 'diff1_income_lowest_quintile_scaled',\n",
    "#  'L1_income_second_quintile_scaled',\n",
    " 'diff1_income_second_quintile_scaled',\n",
    "#  'L1_income_third_quintile_scaled',\n",
    " 'diff1_income_third_quintile_scaled',\n",
    "#  'L1_income_fourth_quintile_scaled',\n",
    " 'diff1_income_fourth_quintile_scaled',\n",
    "#  'L1_income_highest_quintile_scaled',\n",
    " 'diff1_income_highest_quintile_scaled',\n",
    "#  'L1_income_top_5_percent_scaled',\n",
    " 'diff1_income_top_5_percent_scaled',\n",
    "#  'L1_median_gross_rent_scaled',\n",
    " 'diff1_median_gross_rent_scaled',\n",
    "#  'L1_median_monthly_owner_costs_scaled',\n",
    " 'diff1_median_monthly_owner_costs_scaled',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest, for Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = district_train_test_split(dataframe=housevotes_df, \n",
    "                                                             idx_colname='idx',\n",
    "                                                             np_seed=12345, \n",
    "                                                             tts_seed=12345, \n",
    "                                                             test_size=0.2,\n",
    "                                                             cols_for_stratify=['target', 'dmargin_45_55']\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044, 138)\n",
      "(261, 138)\n",
      "Test Accuracy score:  0.9655172413793104\n",
      "Test F1 score:  0.963265306122449\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[features_model_2]\n",
    "X_test = X_test[features_model_2]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "rf = RandomForestClassifier(random_state=23, n_estimators=100)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_class = rf.predict(X_test)\n",
    "y_pred_prob = rf.predict_proba(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[134,   3],\n",
       "       [  6, 118]])"
      ]
     },
     "execution_count": 697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted R wins</th>\n",
       "      <th>Predicted D wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual R wins</th>\n",
       "      <td>134</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual D wins</th>\n",
       "      <td>6</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predicted R wins  Predicted D wins\n",
       "Actual R wins               134                 3\n",
       "Actual D wins                 6               118"
      ]
     },
     "execution_count": 698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(y_test, y_pred_class), columns = ['Predicted R wins', 'Predicted D wins'], \n",
    "             index = ['Actual R wins', 'Actual D wins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dem_L1_wins</td>\n",
       "      <td>0.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dem_L1_voteshare</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dem_L2_voteshare</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dem_incumbent_in_race</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dem_L4_wins</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dem_L2_wins</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dem_L3_wins</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dem_L3_voteshare</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rep_incumbent_in_race</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dem_L5_voteshare</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dem_L4_voteshare</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dem_L5_wins</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ptransport_share</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>renter_share</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>veteran_share</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incumbent_L3_races</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>foreignborn_share</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>incumbent_L5_races</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>incumbent_L4_races</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>median_gross_rent_scaled</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>liveabroad_share</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>white_share</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>asian_share</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>incumbent_L2_races</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>otherrace_share</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>poverty_share</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>median_monthly_owner_costs_scaled</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60_74_share</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>hhinc_50k_less_share</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>hhinc_125k_more_share</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>hs_below_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>income_third_quintile_scaled</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>diff1_18_29_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>diff1_hhinc_100k_more_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>diff1_samehouse_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>diff1_18_above_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>diff1_white_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>diff1_black_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>mortgage_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>diff1_otherrace_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>diff1_nativeoutofstate_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>diff1_foreignborn_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>armedforce_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>diff1_hs_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>diff1_somecollege_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>lfp_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>diff1_samecounty_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>diff1_hhinc_75k_more_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>diff1_diffstate_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>diff1_walktowork_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>f_phd_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>diff1_ingradschool_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>diff1_m_phd_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>diff1_f_graddeg_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>diff1_f_phd_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>diff1_poverty_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>diff1_45_59_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>diff1_hhinc_30k_less_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>diff1_hhinc_50k_less_share</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>diff1_median_monthly_owner_costs_scaled</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature_name importance\n",
       "4                                dem_L1_wins      0.114\n",
       "9                           dem_L1_voteshare      0.080\n",
       "13                          dem_L2_voteshare      0.074\n",
       "14                     dem_incumbent_in_race      0.071\n",
       "6                                dem_L4_wins      0.051\n",
       "8                                dem_L2_wins      0.041\n",
       "7                                dem_L3_wins      0.040\n",
       "12                          dem_L3_voteshare      0.040\n",
       "15                     rep_incumbent_in_race      0.037\n",
       "10                          dem_L5_voteshare      0.032\n",
       "11                          dem_L4_voteshare      0.030\n",
       "5                                dem_L5_wins      0.026\n",
       "41                          ptransport_share      0.025\n",
       "66                              renter_share      0.019\n",
       "61                             veteran_share      0.017\n",
       "2                         incumbent_L3_races      0.016\n",
       "30                         foreignborn_share      0.013\n",
       "0                         incumbent_L5_races      0.013\n",
       "1                         incumbent_L4_races      0.011\n",
       "127                 median_gross_rent_scaled      0.010\n",
       "40                          liveabroad_share      0.009\n",
       "24                               white_share      0.009\n",
       "26                               asian_share      0.008\n",
       "3                         incumbent_L2_races      0.008\n",
       "28                           otherrace_share      0.006\n",
       "52                             poverty_share      0.005\n",
       "128        median_monthly_owner_costs_scaled      0.004\n",
       "22                               60_74_share      0.004\n",
       "55                      hhinc_50k_less_share      0.003\n",
       "58                     hhinc_125k_more_share      0.003\n",
       "..                                       ...        ...\n",
       "31                            hs_below_share      0.001\n",
       "123             income_third_quintile_scaled      0.001\n",
       "71                         diff1_18_29_share      0.001\n",
       "109              diff1_hhinc_100k_more_share      0.001\n",
       "88                     diff1_samehouse_share      0.001\n",
       "70                      diff1_18_above_share      0.001\n",
       "76                         diff1_white_share      0.001\n",
       "77                         diff1_black_share      0.001\n",
       "67                            mortgage_share      0.001\n",
       "80                     diff1_otherrace_share      0.001\n",
       "81              diff1_nativeoutofstate_share      0.001\n",
       "82                   diff1_foreignborn_share      0.001\n",
       "64                          armedforce_share      0.001\n",
       "84                            diff1_hs_share      0.001\n",
       "85                   diff1_somecollege_share      0.001\n",
       "62                                 lfp_share      0.001\n",
       "89                    diff1_samecounty_share      0.001\n",
       "108               diff1_hhinc_75k_more_share      0.001\n",
       "91                     diff1_diffstate_share      0.001\n",
       "94                    diff1_walktowork_share      0.001\n",
       "51                               f_phd_share      0.001\n",
       "98                  diff1_ingradschool_share      0.001\n",
       "101                        diff1_m_phd_share      0.001\n",
       "102                    diff1_f_graddeg_share      0.001\n",
       "103                        diff1_f_phd_share      0.001\n",
       "104                      diff1_poverty_share      0.001\n",
       "73                         diff1_45_59_share      0.001\n",
       "106               diff1_hhinc_30k_less_share      0.001\n",
       "107               diff1_hhinc_50k_less_share      0.001\n",
       "137  diff1_median_monthly_owner_costs_scaled      0.001\n",
       "\n",
       "[138 rows x 2 columns]"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance = pd.DataFrame((zip(X_train.columns, rf.feature_importances_)))\n",
    "feat_importance.columns = ['feature_name', 'importance']\n",
    "feat_importance.importance = feat_importance.importance.apply(lambda x: '%.3f' % x) \n",
    "feat_importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.9616858237547893\n",
      "Test F1 score:  0.9596774193548389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ptw/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[132,   5],\n",
       "       [  5, 119]])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 23,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 130 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.3min finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state = 23)\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, scoring='neg_mean_absolute_error', \n",
    "                              cv = 3, verbose=2, random_state=42, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 600,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 60,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators='warn', n_jobs=None,\n",
       "                                              oob_score=Fa...\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False],\n",
       "                         'max_depth': [50, 60, 70, 80, 90, 100, 110],\n",
       "                         'max_features': [2, 3, 'sqrt'],\n",
       "                         'min_samples_leaf': [3, 4, 5],\n",
       "                         'min_samples_split': [3, 4, 5, 6, 7, 8, 10, 12],\n",
       "                         'n_estimators': [100, 200, 300, 400, 500, 600, 700,\n",
       "                                          800, 900, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [50, 60, 70, 80, 90, 100, 110],\n",
    "    'max_features': [1,2, 3, 'sqrt'],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [3, 4, 5, 6, 7, 8, 10, 12],\n",
    "    'n_estimators': [100]\n",
    "}\n",
    "\n",
    "CV_rfc = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 50,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 3,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_rfc.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.9616858237547893\n",
      "Test F1 score:  0.9596774193548389\n"
     ]
    }
   ],
   "source": [
    "rfc_pred = CV_rfc.best_estimator_.predict(X_test)\n",
    "# checking accuracy\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, rfc_pred))\n",
    "# checking accuracy\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for k in range(1, 36):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_class = knn.predict(X_test)\n",
    "#     print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "#     print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffccc586f28>]"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, 36), scores)  # set k=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score:  0.9693486590038314\n",
      "Test F1 score:  0.9674796747967479\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[134,   3],\n",
       "       [  5, 119]])"
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_class = knn.predict(X_test)\n",
    "print('Test Accuracy score: ', metrics.accuracy_score(y_test, y_pred_class))\n",
    "print('Test F1 score: ', metrics.f1_score(y_test, y_pred_class))\n",
    "metrics.confusion_matrix(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9846743295019157\n",
      "0.946360153256705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95       137\n",
      "           1       0.93      0.96      0.94       124\n",
      "\n",
      "    accuracy                           0.95       261\n",
      "   macro avg       0.95      0.95      0.95       261\n",
      "weighted avg       0.95      0.95      0.95       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_class = AdaBoostClassifier(random_state = 12345)\n",
    "ada_class.fit(X_train, y_train)\n",
    "print(ada_class.score(X_train, y_train))\n",
    "print(ada_class.score(X_test, y_test))\n",
    "pred = ada_class.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9846743295019157\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       137\n",
      "           1       0.98      0.98      0.98       124\n",
      "\n",
      "    accuracy                           0.98       261\n",
      "   macro avg       0.98      0.98      0.98       261\n",
      "weighted avg       0.98      0.98      0.98       261\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_class = XGBClassifier(random_state = 12345)\n",
    "xgb_rf_class = XGBRFClassifier(random_state = 12345)\n",
    "xgb_class.fit(X_train, y_train)\n",
    "print(xgb_class.score(X_train, y_train))\n",
    "print(xgb_class.score(X_test, y_test))\n",
    "pred = xgb_class.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9846743295019157\n",
      "0.9683908045977011\n",
      "0.9808429118773946\n"
     ]
    }
   ],
   "source": [
    "xgb_rf_class.fit(X_train, y_train)\n",
    "print(xgb_rf_class.score(X_train, y_train))\n",
    "print(xgb_rf_class.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[135,   2],\n",
       "       [  2, 122]])"
      ]
     },
     "execution_count": 625,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted R wins</th>\n",
       "      <th>Predicted D wins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual R wins</th>\n",
       "      <td>135</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual D wins</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Predicted R wins  Predicted D wins\n",
       "Actual R wins               135                 2\n",
       "Actual D wins                 2               122"
      ]
     },
     "execution_count": 629,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cm, columns = ['Predicted R wins', 'Predicted D wins'], \n",
    "             index = ['Actual R wins', 'Actual D wins'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "def district_train_test_split(dataframe, idx_colname, np_seed, tts_seed, test_size, cols_for_stratify):\n",
    "    np.random.seed(np_seed)\n",
    "    population = np.arange(1, 436)\n",
    "    sample_1_ids = np.random.choice(population, 200, replace=False)\n",
    "    sample_2_ids = list(set(population) - set(sample_1_ids))\n",
    "    sample_1 = dataframe[dataframe[idx_colname].isin(sample_1_ids)]\n",
    "    sample_2 = dataframe[dataframe[idx_colname].isin(sample_2_ids)]\n",
    "    train_s1, test_s1 = train_test_split(sample_1, \n",
    "                                         test_size=test_size, \n",
    "                                         random_state=tts_seed, \n",
    "                                         stratify=sample_1[cols_for_stratify]\n",
    "                                        )\n",
    "    train_s2, test_s2 = train_test_split(sample_2,\n",
    "                                         test_size=test_size,\n",
    "                                         random_state=tts_seed, \n",
    "                                         stratify=sample_2[cols_for_stratify]\n",
    "                                        )\n",
    "    train = pd.concat([train_s1, train_s2], axis=0)\n",
    "    test = pd.concat([test_s1, test_s2], axis=0)\n",
    "    X_train = train.drop(['target'], axis=True)\n",
    "    y_train = train['target']\n",
    "    X_test = test.drop(['target'], axis=True)\n",
    "    y_test = test['target']\n",
    "\n",
    "#     print('Shape for X_train:', X_train.shape)\n",
    "#     print('Shape for y_train:', y_train.shape)\n",
    "#     print('Shape for X_test:', X_test.shape)\n",
    "#     print('Shape for y_test:', y_test.shape)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = district_train_test_split(dataframe=housevotes_df, \n",
    "                                                             idx_colname='idx',\n",
    "                                                             np_seed=12345, \n",
    "                                                             tts_seed=12345, \n",
    "                                                             test_size=0.2,\n",
    "                                                             cols_for_stratify=['target', 'dmargin_45_55']\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['yr_district_id', 'year_x', 'state', 'district_id_x',\n",
       "       'winner_voteshare', 'total_dem_vote_share', 'total_rep_vote_share',\n",
       "       'dL1_winner', 'dL2_winner', 'dL3_winner',\n",
       "       ...\n",
       "       'L1_income_top_5_percent_scaled', 'diff1_income_top_5_percent_scaled',\n",
       "       'L1_median_gross_rent_scaled', 'diff1_median_gross_rent_scaled',\n",
       "       'L1_median_monthly_owner_costs_scaled',\n",
       "       'diff1_median_monthly_owner_costs_scaled', 'idx', '2014', '2016',\n",
       "       '2018'],\n",
       "      dtype='object', length=281)"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044, 3)\n",
      "(261, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train[['dem_L1_wins','year_x','idx']]\n",
    "X_test = X_test[['dem_L1_wins','year_x','idx']]\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1044,)\n",
      "(1044,)\n"
     ]
    }
   ],
   "source": [
    "clusters_train = X_train['idx']\n",
    "Z_train = X_train['year_x']\n",
    "print(clusters_train.shape)\n",
    "print(Z_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-528-09dec81d3722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmerf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMERF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMERF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mZ_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclusters_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/merf/merf.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Z, clusters, y)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mn_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# random effects dimension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# cast Z to numpy array (required if it's a dataframe, otw, the matrix mults later fail)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from merf.utils import MERFDataGenerator\n",
    "from merf.merf import MERF\n",
    "mrf = MERF(n_estimators=300, max_iterations=100)\n",
    "mrf.fit(X_train,Z_train, clusters_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing (Omer's ideas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(housevotes_df.dem_L2_wins - housevotes_df.dem_L1_wins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_flips_df = housevotes_df[(housevotes_df.target - housevotes_df.dem_L1_wins) != 0]  # flips in either direction\n",
    "test_flips_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(housevotes_df.target - housevotes_df.dem_L1_wins).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flips_df.groupby(['dem_L1_wins', 'dem_L2_wins']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housevotes_df.dem_L2_wins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_test.reset_index(drop=True), pd.Series(y_pred_prob[:, 1]), y_test.reset_index(drop=True)], axis=1)\n",
    "test_df = test_df.rename(columns={0:'predicted_proba'})\n",
    "test_df.loc[(test_df.swing_district == 1) & (test_df.incumbent_in_race == 0), ['dL1_winner', \n",
    "                                                                               'dL1_winner', \n",
    "                                                                               'incumbent_L3_races', \n",
    "                                                                               'incumbent_in_race', \n",
    "#                                                                                'swing_district', \n",
    "                                                                               'predicted_proba', \n",
    "                                                                               'target']]#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap to visualize correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# housevotes_df[features_model_1].corr()[['target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (20,16))\n",
    "# sns.heatmap(housevotes_df[features_model_1].corr(), center=0, annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heatmap to visualize correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>l1_m18_below_share</th>\n",
       "      <td>-0.061401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_m18_below_share</th>\n",
       "      <td>-0.050238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_f18_below_share</th>\n",
       "      <td>-0.100208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_f18_below_share</th>\n",
       "      <td>-0.039914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_18_below_share</th>\n",
       "      <td>-0.084387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_18_below_share</th>\n",
       "      <td>-0.058963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_m18_above_share</th>\n",
       "      <td>0.061401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_m18_above_share</th>\n",
       "      <td>0.050238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_f18_above_share</th>\n",
       "      <td>0.100208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_f18_above_share</th>\n",
       "      <td>0.039914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_18_above_share</th>\n",
       "      <td>0.084387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_18_above_share</th>\n",
       "      <td>0.058963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_m18_29_share</th>\n",
       "      <td>0.329917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_m18_29_share</th>\n",
       "      <td>-0.037316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_f18_29_share</th>\n",
       "      <td>0.340311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_f18_29_share</th>\n",
       "      <td>-0.032791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_18_29_share</th>\n",
       "      <td>0.339662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_18_29_share</th>\n",
       "      <td>-0.045975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_m30_44_share</th>\n",
       "      <td>0.321335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_m30_44_share</th>\n",
       "      <td>0.088118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_f30_44_share</th>\n",
       "      <td>0.317166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_f30_44_share</th>\n",
       "      <td>0.073066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_30_44_share</th>\n",
       "      <td>0.324930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_30_44_share</th>\n",
       "      <td>0.102484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_m45_59_share</th>\n",
       "      <td>-0.131973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_m45_59_share</th>\n",
       "      <td>0.022928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_f45_59_share</th>\n",
       "      <td>-0.132456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_f45_59_share</th>\n",
       "      <td>0.022190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_45_59_share</th>\n",
       "      <td>-0.134529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_45_59_share</th>\n",
       "      <td>0.027758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_m60_74_share</th>\n",
       "      <td>-0.302252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_m60_74_share</th>\n",
       "      <td>-0.014903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_f60_74_share</th>\n",
       "      <td>-0.262178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_f60_74_share</th>\n",
       "      <td>-0.015806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_60_74_share</th>\n",
       "      <td>-0.282985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_60_74_share</th>\n",
       "      <td>-0.019065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_m75_above_share</th>\n",
       "      <td>-0.213380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_m75_above_share</th>\n",
       "      <td>-0.005399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_f75_above_share</th>\n",
       "      <td>-0.170471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_f75_above_share</th>\n",
       "      <td>-0.006732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_75_above_share</th>\n",
       "      <td>-0.228210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_75_above_share</th>\n",
       "      <td>-0.006955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_white_share</th>\n",
       "      <td>-0.517666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_white_share</th>\n",
       "      <td>-0.034835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_black_share</th>\n",
       "      <td>0.259261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_black_share</th>\n",
       "      <td>-0.018454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_asian_share</th>\n",
       "      <td>0.362590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_asian_share</th>\n",
       "      <td>0.037146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_hispanic_share</th>\n",
       "      <td>0.322507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff1_hispanic_share</th>\n",
       "      <td>0.021796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         target\n",
       "l1_m18_below_share    -0.061401\n",
       "diff1_m18_below_share -0.050238\n",
       "l1_f18_below_share    -0.100208\n",
       "diff1_f18_below_share -0.039914\n",
       "l1_18_below_share     -0.084387\n",
       "diff1_18_below_share  -0.058963\n",
       "l1_m18_above_share     0.061401\n",
       "diff1_m18_above_share  0.050238\n",
       "l1_f18_above_share     0.100208\n",
       "diff1_f18_above_share  0.039914\n",
       "l1_18_above_share      0.084387\n",
       "diff1_18_above_share   0.058963\n",
       "l1_m18_29_share        0.329917\n",
       "diff1_m18_29_share    -0.037316\n",
       "l1_f18_29_share        0.340311\n",
       "diff1_f18_29_share    -0.032791\n",
       "l1_18_29_share         0.339662\n",
       "diff1_18_29_share     -0.045975\n",
       "l1_m30_44_share        0.321335\n",
       "diff1_m30_44_share     0.088118\n",
       "l1_f30_44_share        0.317166\n",
       "diff1_f30_44_share     0.073066\n",
       "l1_30_44_share         0.324930\n",
       "diff1_30_44_share      0.102484\n",
       "l1_m45_59_share       -0.131973\n",
       "diff1_m45_59_share     0.022928\n",
       "l1_f45_59_share       -0.132456\n",
       "diff1_f45_59_share     0.022190\n",
       "l1_45_59_share        -0.134529\n",
       "diff1_45_59_share      0.027758\n",
       "l1_m60_74_share       -0.302252\n",
       "diff1_m60_74_share    -0.014903\n",
       "l1_f60_74_share       -0.262178\n",
       "diff1_f60_74_share    -0.015806\n",
       "l1_60_74_share        -0.282985\n",
       "diff1_60_74_share     -0.019065\n",
       "l1_m75_above_share    -0.213380\n",
       "diff1_m75_above_share -0.005399\n",
       "l1_f75_above_share    -0.170471\n",
       "diff1_f75_above_share -0.006732\n",
       "l1_75_above_share     -0.228210\n",
       "diff1_75_above_share  -0.006955\n",
       "l1_white_share        -0.517666\n",
       "diff1_white_share     -0.034835\n",
       "l1_black_share         0.259261\n",
       "diff1_black_share     -0.018454\n",
       "l1_asian_share         0.362590\n",
       "diff1_asian_share      0.037146\n",
       "l1_hispanic_share      0.322507\n",
       "diff1_hispanic_share   0.021796"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housevotes_df[features_model_2 + ['target']].corr()[['target']][:50]#.shape\n",
    "housevotes_df[features_model_2 + ['target']].corr()[['target']][50:100]#.shape\n",
    "housevotes_df[features_model_2 + ['target']].corr()[['target']][100:150]#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do:\n",
    "\n",
    "- Try MERF, logistic, knn\n",
    "- baseline model: always predict what it was before (using just 1 lag term)\n",
    "- check all columns are supposed to be there\n",
    "- dig into exact observations where it changed to 1 in 2018, what is driving the prediction there\n",
    "- build a model with swing states (the 60) matched on 60 non-swings, try with other estimators too (logistic, SVM, etc.)\n",
    "\n",
    "Later:\n",
    "- grid search for hyperparameter tuning\n",
    "- k-folds cross validataion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
